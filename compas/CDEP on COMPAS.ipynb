{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/irenetrampoline/compas-python/blob/master/COMPAS_Python.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.stats import pearsonr\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from score_funcs import cdep\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from model import  Net\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch\n",
    "import torch\n",
    "from model import Net\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "torch.backends.cudnn.deterministic = True #this makes results reproducible. \n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 7214\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../../compas-analysis/compas-scores-two-years.csv')\n",
    "print('Num rows: %d' %len(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows filtered: 6172\n"
     ]
    }
   ],
   "source": [
    "df = raw_data[((raw_data['days_b_screening_arrest'] <=30) & \n",
    "      (raw_data['days_b_screening_arrest'] >= -30) &\n",
    "      (raw_data['is_recid'] != -1) &\n",
    "      (raw_data['c_charge_degree'] != 'O') & \n",
    "      (raw_data['score_text'] != 'N/A')\n",
    "     )].copy()\n",
    "\n",
    "print('Num rows filtered: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crimes = df.c_charge_desc.value_counts().to_frame()\n",
    "crimes['description'] = crimes.index\n",
    "crimes['classified']= False\n",
    "words = ['Battery', 'Assault','Violence', 'no charge', 'Possession', 'Poss', 'Pos', 'Theft', 'Driving', 'DUI', 'Burglary', 'Drivers','Cocaine', 'License','Abuse']\n",
    "for word in words:\n",
    "    crimes['classified'] = crimes['description'].str.contains(word) | crimes['classified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   c_charge_desc  \\\n",
      "Battery                                     1087   \n",
      "arrest case no charge                        784   \n",
      "Possession of Cocaine                        419   \n",
      "Grand Theft in the 3rd Degree                384   \n",
      "Driving While License Revoked                189   \n",
      "Driving Under The Influence                  126   \n",
      "Felony Driving While Lic Suspd                93   \n",
      "Pos Cannabis W/Intent Sel/Del                 93   \n",
      "Felony Battery (Dom Strang)                   92   \n",
      "Grand Theft (Motor Vehicle)                   92   \n",
      "Possess Cannabis/20 Grams Or Less             79   \n",
      "Burglary Unoccupied Dwelling                  77   \n",
      "DUI Property Damage/Injury                    70   \n",
      "Burglary Conveyance Unoccup                   68   \n",
      "Poss3,4 Methylenedioxymethcath                68   \n",
      "Possession of Cannabis                        68   \n",
      "Felony Petit Theft                            60   \n",
      "Aggrav Battery w/Deadly Weapon                57   \n",
      "DUI Level 0.15 Or Minor In Veh                54   \n",
      "Aggravated Assault W/Dead Weap                54   \n",
      "Aggravated Battery / Pregnant                 48   \n",
      "Uttering a Forged Instrument                  47   \n",
      "Viol Injunct Domestic Violence                47   \n",
      "Resist Officer w/Violence                     46   \n",
      "Battery on Law Enforc Officer                 46   \n",
      "Tampering With Physical Evidence              46   \n",
      "Susp Drivers Lic 1st Offense                  45   \n",
      "Possession Of Alprazolam                      44   \n",
      "Driving License Suspended                     44   \n",
      "Felony Battery w/Prior Convict                38   \n",
      "Assault                                       38   \n",
      "Poss Pyrrolidinovalerophenone                 37   \n",
      "Resist/Obstruct W/O Violence                  36   \n",
      "Burglary Structure Unoccup                    35   \n",
      "Aggravated Assault W/dead Weap                34   \n",
      "Carrying Concealed Firearm                    34   \n",
      "Agg Battery Grt/Bod/Harm                      31   \n",
      "Possession Burglary Tools                     29   \n",
      "Petit Theft                                   29   \n",
      "Operating W/O Valid License                   28   \n",
      "Disorderly Conduct                            27   \n",
      "Crim Use of Personal ID Info                  26   \n",
      "Possession Of Methamphetamine                 26   \n",
      "Burglary Dwelling Occupied                    26   \n",
      "False Imprisonment                            24   \n",
      "Deliver Cocaine                               23   \n",
      "Possession of Oxycodone                       22   \n",
      "Aggravated Assault w/Firearm                  22   \n",
      "Possession Of Heroin                          21   \n",
      "Tamper With Witness/Victim/CI                 21   \n",
      "Poss Contr Subst W/o Prescript                21   \n",
      "\n",
      "                                                         description  \\\n",
      "Battery                                                      Battery   \n",
      "arrest case no charge                          arrest case no charge   \n",
      "Possession of Cocaine                          Possession of Cocaine   \n",
      "Grand Theft in the 3rd Degree          Grand Theft in the 3rd Degree   \n",
      "Driving While License Revoked          Driving While License Revoked   \n",
      "Driving Under The Influence              Driving Under The Influence   \n",
      "Felony Driving While Lic Suspd        Felony Driving While Lic Suspd   \n",
      "Pos Cannabis W/Intent Sel/Del          Pos Cannabis W/Intent Sel/Del   \n",
      "Felony Battery (Dom Strang)              Felony Battery (Dom Strang)   \n",
      "Grand Theft (Motor Vehicle)              Grand Theft (Motor Vehicle)   \n",
      "Possess Cannabis/20 Grams Or Less  Possess Cannabis/20 Grams Or Less   \n",
      "Burglary Unoccupied Dwelling            Burglary Unoccupied Dwelling   \n",
      "DUI Property Damage/Injury                DUI Property Damage/Injury   \n",
      "Burglary Conveyance Unoccup              Burglary Conveyance Unoccup   \n",
      "Poss3,4 Methylenedioxymethcath        Poss3,4 Methylenedioxymethcath   \n",
      "Possession of Cannabis                        Possession of Cannabis   \n",
      "Felony Petit Theft                                Felony Petit Theft   \n",
      "Aggrav Battery w/Deadly Weapon        Aggrav Battery w/Deadly Weapon   \n",
      "DUI Level 0.15 Or Minor In Veh        DUI Level 0.15 Or Minor In Veh   \n",
      "Aggravated Assault W/Dead Weap        Aggravated Assault W/Dead Weap   \n",
      "Aggravated Battery / Pregnant          Aggravated Battery / Pregnant   \n",
      "Uttering a Forged Instrument            Uttering a Forged Instrument   \n",
      "Viol Injunct Domestic Violence        Viol Injunct Domestic Violence   \n",
      "Resist Officer w/Violence                  Resist Officer w/Violence   \n",
      "Battery on Law Enforc Officer          Battery on Law Enforc Officer   \n",
      "Tampering With Physical Evidence    Tampering With Physical Evidence   \n",
      "Susp Drivers Lic 1st Offense            Susp Drivers Lic 1st Offense   \n",
      "Possession Of Alprazolam                    Possession Of Alprazolam   \n",
      "Driving License Suspended                  Driving License Suspended   \n",
      "Felony Battery w/Prior Convict        Felony Battery w/Prior Convict   \n",
      "Assault                                                      Assault   \n",
      "Poss Pyrrolidinovalerophenone          Poss Pyrrolidinovalerophenone   \n",
      "Resist/Obstruct W/O Violence            Resist/Obstruct W/O Violence   \n",
      "Burglary Structure Unoccup                Burglary Structure Unoccup   \n",
      "Aggravated Assault W/dead Weap        Aggravated Assault W/dead Weap   \n",
      "Carrying Concealed Firearm                Carrying Concealed Firearm   \n",
      "Agg Battery Grt/Bod/Harm                    Agg Battery Grt/Bod/Harm   \n",
      "Possession Burglary Tools                  Possession Burglary Tools   \n",
      "Petit Theft                                              Petit Theft   \n",
      "Operating W/O Valid License              Operating W/O Valid License   \n",
      "Disorderly Conduct                                Disorderly Conduct   \n",
      "Crim Use of Personal ID Info            Crim Use of Personal ID Info   \n",
      "Possession Of Methamphetamine          Possession Of Methamphetamine   \n",
      "Burglary Dwelling Occupied                Burglary Dwelling Occupied   \n",
      "False Imprisonment                                False Imprisonment   \n",
      "Deliver Cocaine                                      Deliver Cocaine   \n",
      "Possession of Oxycodone                      Possession of Oxycodone   \n",
      "Aggravated Assault w/Firearm            Aggravated Assault w/Firearm   \n",
      "Possession Of Heroin                            Possession Of Heroin   \n",
      "Tamper With Witness/Victim/CI          Tamper With Witness/Victim/CI   \n",
      "Poss Contr Subst W/o Prescript        Poss Contr Subst W/o Prescript   \n",
      "\n",
      "                                   classified  \n",
      "Battery                                  True  \n",
      "arrest case no charge                    True  \n",
      "Possession of Cocaine                    True  \n",
      "Grand Theft in the 3rd Degree            True  \n",
      "Driving While License Revoked            True  \n",
      "Driving Under The Influence              True  \n",
      "Felony Driving While Lic Suspd           True  \n",
      "Pos Cannabis W/Intent Sel/Del            True  \n",
      "Felony Battery (Dom Strang)              True  \n",
      "Grand Theft (Motor Vehicle)              True  \n",
      "Possess Cannabis/20 Grams Or Less        True  \n",
      "Burglary Unoccupied Dwelling             True  \n",
      "DUI Property Damage/Injury               True  \n",
      "Burglary Conveyance Unoccup              True  \n",
      "Poss3,4 Methylenedioxymethcath           True  \n",
      "Possession of Cannabis                   True  \n",
      "Felony Petit Theft                       True  \n",
      "Aggrav Battery w/Deadly Weapon           True  \n",
      "DUI Level 0.15 Or Minor In Veh           True  \n",
      "Aggravated Assault W/Dead Weap           True  \n",
      "Aggravated Battery / Pregnant            True  \n",
      "Uttering a Forged Instrument            False  \n",
      "Viol Injunct Domestic Violence           True  \n",
      "Resist Officer w/Violence                True  \n",
      "Battery on Law Enforc Officer            True  \n",
      "Tampering With Physical Evidence        False  \n",
      "Susp Drivers Lic 1st Offense             True  \n",
      "Possession Of Alprazolam                 True  \n",
      "Driving License Suspended                True  \n",
      "Felony Battery w/Prior Convict           True  \n",
      "Assault                                  True  \n",
      "Poss Pyrrolidinovalerophenone            True  \n",
      "Resist/Obstruct W/O Violence             True  \n",
      "Burglary Structure Unoccup               True  \n",
      "Aggravated Assault W/dead Weap           True  \n",
      "Carrying Concealed Firearm              False  \n",
      "Agg Battery Grt/Bod/Harm                 True  \n",
      "Possession Burglary Tools                True  \n",
      "Petit Theft                              True  \n",
      "Operating W/O Valid License              True  \n",
      "Disorderly Conduct                      False  \n",
      "Crim Use of Personal ID Info            False  \n",
      "Possession Of Methamphetamine            True  \n",
      "Burglary Dwelling Occupied               True  \n",
      "False Imprisonment                      False  \n",
      "Deliver Cocaine                          True  \n",
      "Possession of Oxycodone                  True  \n",
      "Aggravated Assault w/Firearm             True  \n",
      "Possession Of Heroin                     True  \n",
      "Tamper With Witness/Victim/CI           False  \n",
      "Poss Contr Subst W/o Prescript           True  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(crimes[crimes.c_charge_desc >20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c_charge_desc'] = df['c_charge_desc'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_book = {'possession' : ['Possession'  'Poss', 'Cocaine','Cannabis'],\n",
    "'violence' : ['Battery','Assault', 'Violence', 'Abuse'],\n",
    "'theft' : ['Theft', 'Burglary', ],\n",
    "'driving' : ['Drivers', 'Driving', 'License', 'Drivers', 'DUI','Veh'],\n",
    "'nocharge' : ['no charge'],}\n",
    "df['classified'] = 0\n",
    "\n",
    "for key in black_book.keys():\n",
    "    df[key] = 0\n",
    "    for word in black_book[key]:\n",
    "        df[key]= df[key] +   df['c_charge_desc'].str.contains(word).astype(bool).astype(int)\n",
    "        df['classified'] =df['classified'] |  df['c_charge_desc'].str.contains(word).astype(bool).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.get_dummies(df['c_charge_degree'],prefix='crimefactor',drop_first=True)\n",
    "df_age = pd.get_dummies(df['age_cat'],prefix='age')\n",
    "df_race = pd.get_dummies(df['race'],prefix='race')\n",
    "df_gender = pd.get_dummies(df['sex'],prefix='sex',drop_first=True)\n",
    "df_score = pd.get_dummies(df['score_text'] != 'Low',prefix='score_factor',drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = pd.concat([df_race, df_crime, df_age,df_gender,\n",
    "                   df['priors_count'],\n",
    "                   df['theft'],\n",
    "                   df['driving'],\n",
    "                   df['possession'],\n",
    "                   df['violence'],\n",
    "                   df['nocharge']\n",
    "                  ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  torch.tensor(df_lr.values).float()\n",
    "y= torch.tensor(df['two_year_recid'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x,y)\n",
    "num_total = len(dataset)\n",
    "num_train = int(0.8 * num_total)\n",
    "num_val = int(0.1 * num_total)\n",
    "num_test = num_total - num_train - num_val\n",
    "torch.manual_seed(0);\n",
    "train_dataset, test_dataset ,val_dataset= torch.utils.data.random_split(dataset, [num_train, num_test, num_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'train' : train_dataset, 'test':test_dataset, 'val': val_dataset}\n",
    "dataset_sizes = {'train' : len(train_dataset), 'test':len(test_dataset), 'val': len(val_dataset)}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=256, \n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'test','val']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'seed':[], 'regularizer_rate':[],\n",
    "                    \"test_acc\":[], \n",
    "                    \"test_loss\":[],\n",
    "                   'black_wc': [],\n",
    "                   'black_wf':[],\n",
    "                   'white_wc':[],\n",
    "                   'white_wf':[],\n",
    "                   \n",
    "                   'insensitivity':[]}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "patience = 10\n",
    "num_epochs =1000\n",
    "\n",
    "weights = np.asarray([len(datasets['train'])/(datasets['train'].dataset[datasets['train'].indices][1]==0).sum().item(), len(train_dataset)/datasets['train'].dataset[datasets['train'].indices][1].sum().item()])\n",
    "weights /= weights.sum()\n",
    "weights = torch.tensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = weights.double().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_race = np.zeros((17))\n",
    "blob_race[:] =1\n",
    "blob_norace = np.zeros((17))\n",
    "blob_norace[6:] = 1\n",
    "def train( model, device, train_loader, optimizer, epoch, regularizer_rate):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "         \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss =criterion(output, target)\n",
    "        add_loss = torch.zeros(1,).cuda()\n",
    "        if regularizer_rate != 0:\n",
    "            add_loss += cdep(model, data, blob_norace) \n",
    "        (loss+regularizer_rate*add_loss).backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            acc = 100.*pred.eq(target.view_as(pred)).sum().item()/len(target)\n",
    "\n",
    "def test(model, device, test_loader, epoch, verbose = False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data[:,:6] =0\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "#     s.losses_test.append(test_loss)\n",
    "#     s.accs_test.append(100. * correct / len(test_loader.dataset))\n",
    "    return test_loss,test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'seed':[], 'regularizer_rate':[],\n",
    "                    \"test_acc\":[], \n",
    "                    \"test_loss\":[],\n",
    "                   'black_wc': [],\n",
    "                   'black_wf':[],\n",
    "                   'white_wc':[],\n",
    "                   'white_wf':[],\n",
    "                    'weights' :[],\n",
    "                   \n",
    "                   'insensitivity':[]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1531a27beb348229fe2433c6958be38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6211, Accuracy: 409/617 (66%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa0c03f5cfc4456a90986974e7b9b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6031, Accuracy: 424/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922a3538ba614013ae8fb22a04f981f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6044, Accuracy: 416/617 (67%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3778785b2f4991bf8d8a0257c66d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5908, Accuracy: 426/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc16bd52cf8d4279b4f3d860f8b76604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6015, Accuracy: 425/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc52269d6c40485d9826975b57760b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5987, Accuracy: 421/617 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce0971a89a849ff95b0d034eda5d310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6113, Accuracy: 421/617 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8932b997144cd5b18d1fe951951e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5979, Accuracy: 425/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e37f9829a8f4618ab4f8220f486146d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5973, Accuracy: 422/617 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1e4b7b87f3404a8d165d7a474b3247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5945, Accuracy: 426/617 (69%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regularizer_rates = [0,1]\n",
    "val_x, val_y = val_dataset.dataset[val_dataset.indices] #needed for calculating race specific accs\n",
    "for seed in range(5):\n",
    "    for regularizer_rate  in regularizer_rates:\n",
    "        torch.manual_seed(seed) #weight init is varied\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        best_model_weights = None\n",
    "        best_test_loss = 100000\n",
    "\n",
    "        cur_patience = 0\n",
    "        net = Net().cuda()\n",
    "        optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum =0.9)\n",
    "        for epoch in tqdm_notebook(range(num_epochs)):\n",
    "\n",
    "            train( net, device, dataloaders['train'], optimizer, epoch, regularizer_rate)\n",
    "            test_loss = test(net, device, dataloaders['test'], epoch)\n",
    "            if test_loss[0] < best_test_loss:\n",
    "\n",
    "                cur_patience = 0\n",
    "                best_test_loss = test_loss[0]\n",
    "                best_model_weights = deepcopy(net.state_dict())\n",
    "            else:\n",
    "                cur_patience +=1\n",
    "                if cur_patience > patience:\n",
    "                    break\n",
    "        net.load_state_dict(best_model_weights)\n",
    "        test_loss, test_acc = test(net, device, dataloaders['val'], epoch+1, verbose = True)\n",
    "\n",
    "\n",
    "        val_out = net(val_x.cuda())\n",
    "        def calc_fairness(race_int):\n",
    "            black_mask = (val_x[:, race_int] ==1).bool() #\n",
    "            val_out_black = val_out.argmax(dim=1).cpu().masked_select(black_mask)\n",
    "            val_y_black = val_y.cpu().masked_select(black_mask)\n",
    "            fp = ((val_out_black ==1)*(val_y_black ==0)).sum().item()\n",
    "            tp = ((val_out_black ==1)*(val_y_black ==1)).sum().item()\n",
    "            fn = ((val_out_black ==0)*(val_y_black ==1)).sum().item()\n",
    "            tn = ((val_out_black ==0)*(val_y_black ==0)).sum().item()\n",
    "            wrongly_incarcerated = fp/(tn+fp)\n",
    "            wrongly_let_go = fn/(tp+fn)\n",
    "            return (wrongly_incarcerated, wrongly_let_go)\n",
    "\n",
    "        black_wc, black_wf = calc_fairness(0)\n",
    "        white_wc, white_wf = calc_fairness(2)\n",
    "#         diff_black, diff_white = test_change(net)\n",
    "        df1 = df1.append(pd.DataFrame({'seed': [seed], 'regularizer_rate':[regularizer_rate],\n",
    "                        \"test_acc\":[test_acc], \n",
    "                        \"test_loss\":[test_loss],\n",
    "                       'black_wc': [black_wc],\n",
    "                       'black_wf':[black_wf],\n",
    "                       'white_wc':[white_wc],\n",
    "                       'white_wf':[white_wf],\n",
    "                                       \n",
    "                       'weights':[best_model_weights],\n",
    "                        'insensitivity' :0 }))\n",
    "df1['equalized_odds_wc'] = df1['black_wc'] / df1['white_wc'] \n",
    "df1['equalized_odds_wf'] = df1['black_wf'] / df1['white_wf'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>black_wc</th>\n",
       "      <th>white_wc</th>\n",
       "      <th>equalized_odds_wc</th>\n",
       "      <th>equalized_odds_wf</th>\n",
       "      <th>black_wf</th>\n",
       "      <th>white_wf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>67.84</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>68.78</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_acc  black_wc  white_wc  equalized_odds_wc  \\\n",
       "regularizer_rate                                                    \n",
       "0.0                  67.84      0.47      0.22               2.17   \n",
       "1.0                  68.78      0.39      0.20               1.91   \n",
       "\n",
       "                  equalized_odds_wf  black_wf  white_wf  \n",
       "regularizer_rate                                         \n",
       "0.0                            0.54      0.24      0.44  \n",
       "1.0                            0.56      0.27      0.48  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(['regularizer_rate']).mean()[['test_acc', 'black_wc', 'white_wc', 'equalized_odds_wc','equalized_odds_wf', 'black_wf', 'white_wf']].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with sensitive attribute hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_race = np.zeros((17))\n",
    "blob_race[:] =1\n",
    "blob_norace = np.zeros((17))\n",
    "blob_norace[6:] = 1\n",
    "def train( model, device, train_loader, optimizer, epoch, regularizer_rate):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data[:,:6] = 0\n",
    "\n",
    "         \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss =criterion(output, target)\n",
    "        add_loss = torch.zeros(1,).cuda()\n",
    "\n",
    "        (loss).backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            acc = 100.*pred.eq(target.view_as(pred)).sum().item()/len(target)\n",
    "\n",
    "def test(model, device, test_loader, epoch, verbose = False,):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data[:,:6] =0\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "#     s.losses_test.append(test_loss)\n",
    "#     s.accs_test.append(100. * correct / len(test_loader.dataset))\n",
    "    return test_loss,test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847a914fd3ef498097f387aaa5471270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6038, Accuracy: 424/617 (69%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.local/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f806b9883ebb4b0c863b554f4ad51ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6033, Accuracy: 419/617 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0411dfa022545e3aaa4876937963e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5964, Accuracy: 423/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6dc6556a9b4e5cbb0e40f00c257e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6046, Accuracy: 424/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678b7c4305db4c37913701d1faed5582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6050, Accuracy: 423/617 (69%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regularizer_rates = [-1]\n",
    "val_x, val_y = val_dataset.dataset[val_dataset.indices] #needed for calculating race specific accs\n",
    "for seed in range(5):\n",
    "    for regularizer_rate  in regularizer_rates:\n",
    "        torch.manual_seed(seed) #weight init is varied\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        best_model_weights = None\n",
    "        best_test_loss = 100000\n",
    "\n",
    "        cur_patience = 0\n",
    "        net = Net().cuda()\n",
    "        optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum =0.9)\n",
    "        for epoch in tqdm_notebook(range(num_epochs)):\n",
    "\n",
    "            train( net, device, dataloaders['train'], optimizer, epoch, regularizer_rate)\n",
    "            test_loss = test(net, device, dataloaders['test'], epoch)\n",
    "            if test_loss[0] < best_test_loss:\n",
    "\n",
    "                cur_patience = 0\n",
    "                best_test_loss = test_loss[0]\n",
    "                best_model_weights = deepcopy(net.state_dict())\n",
    "            else:\n",
    "                cur_patience +=1\n",
    "                if cur_patience > patience:\n",
    "                    break\n",
    "        net.load_state_dict(best_model_weights)\n",
    "        test_loss, test_acc = test(net, device, dataloaders['val'], epoch+1, verbose = True)\n",
    "\n",
    "\n",
    "        \n",
    "        def calc_fairness(race_int):\n",
    "            black_mask = (val_x[:, race_int] ==1).bool() #\n",
    "            val_x_copy = val_x.clone().detach().cuda()\n",
    "            val_x_copy[:,:6] =0\n",
    "            val_out = net(val_x_copy.cuda())\n",
    "            val_out_black = val_out.argmax(dim=1).cpu().masked_select(black_mask)\n",
    "            val_y_black = val_y.cpu().masked_select(black_mask)\n",
    "            fp = ((val_out_black ==1)*(val_y_black ==0)).sum().item()\n",
    "            tp = ((val_out_black ==1)*(val_y_black ==1)).sum().item()\n",
    "            fn = ((val_out_black ==0)*(val_y_black ==1)).sum().item()\n",
    "            tn = ((val_out_black ==0)*(val_y_black ==0)).sum().item()\n",
    "            wrongly_incarcerated = fp/(tn+fp)\n",
    "            wrongly_let_go = fn/(tp+fn)\n",
    "            return (wrongly_incarcerated, wrongly_let_go)\n",
    "\n",
    "        black_wc, black_wf = calc_fairness(0)\n",
    "        white_wc, white_wf = calc_fairness(2)\n",
    "#         diff_black, diff_white = test_change(net)\n",
    "        df1 = df1.append(pd.DataFrame({'seed': [seed], 'regularizer_rate':[regularizer_rate],\n",
    "                        \"test_acc\":[test_acc], \n",
    "                        \"test_loss\":[test_loss],\n",
    "                       'black_wc': [black_wc],\n",
    "                       'black_wf':[black_wf],\n",
    "                       'white_wc':[white_wc],\n",
    "                       'white_wf':[white_wf],\n",
    "                                       \n",
    "                       'weights':[best_model_weights],\n",
    "                        'insensitivity' :0 }))\n",
    "df1['equalized_odds_wc'] = df1['black_wc'] / df1['white_wc'] \n",
    "df1['equalized_odds_wf'] = df1['black_wf'] / df1['white_wf'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regularizer rate -1 refers to the network trained blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>black_wc</th>\n",
       "      <th>white_wc</th>\n",
       "      <th>equalized_odds_wc</th>\n",
       "      <th>equalized_odds_wf</th>\n",
       "      <th>black_wf</th>\n",
       "      <th>white_wf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>68.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>67.84</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>68.78</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_acc  black_wc  white_wc  equalized_odds_wc  \\\n",
       "regularizer_rate                                                    \n",
       "-1.0                 68.49      0.44      0.23               1.96   \n",
       " 0.0                 67.84      0.47      0.22               2.17   \n",
       " 1.0                 68.78      0.39      0.20               1.91   \n",
       "\n",
       "                  equalized_odds_wf  black_wf  white_wf  \n",
       "regularizer_rate                                         \n",
       "-1.0                           0.58      0.24      0.42  \n",
       " 0.0                           0.54      0.24      0.44  \n",
       " 1.0                           0.56      0.27      0.48  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(['regularizer_rate']).mean()[['test_acc', 'black_wc', 'white_wc', 'equalized_odds_wc','equalized_odds_wf', 'black_wf', 'white_wf']].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>black_wc</th>\n",
       "      <th>white_wc</th>\n",
       "      <th>equalized_odds_wc</th>\n",
       "      <th>equalized_odds_wf</th>\n",
       "      <th>black_wf</th>\n",
       "      <th>white_wf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_acc  black_wc  white_wc  equalized_odds_wc  \\\n",
       "regularizer_rate                                                    \n",
       "-1.0                  0.34      0.02      0.01               0.06   \n",
       " 0.0                  1.02      0.03      0.03               0.23   \n",
       " 1.0                  0.34      0.04      0.01               0.16   \n",
       "\n",
       "                  equalized_odds_wf  black_wf  white_wf  \n",
       "regularizer_rate                                         \n",
       "-1.0                           0.02      0.01      0.01  \n",
       " 0.0                           0.03      0.02      0.04  \n",
       " 1.0                           0.03      0.02      0.02  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(['regularizer_rate']).std()[['test_acc', 'black_wc', 'white_wc', 'equalized_odds_wc','equalized_odds_wf', 'black_wf', 'white_wf']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
