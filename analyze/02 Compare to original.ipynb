{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "# compare how much divergence between model 1 trained and original model for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "sys.path.append('../../acd')\n",
    "sys.path.append('../../acd/visualization')\n",
    "sys.path.append('../../acd/acd/util')\n",
    "sys.path.append('../../acd/acd/scores')\n",
    "sys.path.append('../../acd/acd/agglomeration')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from model import LSTMSentiment\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isdir\n",
    "import viz_1d as viz\n",
    "import tiling_1d as tiling\n",
    "import agg_1d as agg\n",
    "import cd\n",
    "import score_funcs\n",
    "import dsets\n",
    "from dsets.sst import dset\n",
    "from dsets.sst.model import LSTMSentiment\n",
    "# check out how two models differ\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from tqdm import tqdm_notebook, tqdm \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_pkl = pickle.load(open('../../acd/dsets/sst/sst.pkl', 'rb'))\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_cache = os.path.join(os.getcwd(), '../data/.vector_cache/input_vectors.pt')\n",
    "word_vectors ='glove.6B.300d'\n",
    "batch_size=  50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_folder = '../models/trained_models'\n",
    "init_model_folder = '../models/init_models'\n",
    "trained_list = os.listdir(trained_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.conda/envs/gpu_usage/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'model.LSTMSentiment' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "init_models = os.listdir(init_model_folder)\n",
    "init_model =torch.load(join(init_model_folder, init_models[0]))\n",
    "init_comp_model =torch.load(join(init_model_folder, init_models[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69416f106fc243739ab58920a1a864af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fnames = sorted([oj(trained_model_folder, fname) for fname in os.listdir(trained_model_folder)]) # filenames in the directory\n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in tqdm_notebook(fnames) ] \n",
    "results = pd.concat(results_list, axis=1).T.infer_objects() # pandas dataframe w/ hyperparams and weights stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "\n",
    "inputs = data.Field(lower= True)\n",
    "answers = data.Field(sequential=False, unk_token=None)\n",
    "\n",
    "train, dev, test = datasets.SST.splits(inputs, answers, fine_grained=False, train_subtrees=True,\n",
    "                                       filter_pred=lambda ex: ex.label != 'neutral')\n",
    "\n",
    "inputs.build_vocab(train, dev, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_vectors:\n",
    "    if os.path.isfile(vector_cache):\n",
    "        inputs.vocab.vectors = torch.load(vector_cache)\n",
    "    else:\n",
    "        inputs.vocab.load_vectors(word_vectors)\n",
    "        makedirs(os.path.dirname(vector_cache))\n",
    "        torch.save(inputs.vocab.vectors,vector_cache)\n",
    "answers.build_vocab(train)\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, dev, test), batch_size=batch_size, device=torch.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = deepcopy(init_model)\n",
    "trained_model.load_state_dict(results['model_weights'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38132415712545803\n"
     ]
    }
   ],
   "source": [
    "print(calulcate_divergence(init_model, init_comp_model, dev)) #divergence between the two original models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c063ede9ce4144b46816e3fe5010e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "divergence_comp = []\n",
    "trained_model = deepcopy(init_model)\n",
    "for i in tqdm_notebook(range(len(results))):\n",
    "    trained_model.load_state_dict(results['comp_model_weights'][i])\n",
    "    divergence_comp.append(calc_expl_divergence(trained_model, init_model, dev))\n",
    "results['divergence_comp'] = divergence_comp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40db53750eca400bb24ab03041f1f394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "divergence = []\n",
    "trained_model = deepcopy(init_model)\n",
    "for i in tqdm_notebook(range(len(results))):\n",
    "    trained_model.load_state_dict(results['model_weights'][i])\n",
    "    divergence.append(calc_expl_divergence(trained_model, init_comp_model, dev))\n",
    "results['divergence'] = divergence    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['train_both', 'sparse_signal', 'signal_strength', 'starting_folder',\n",
       "       'num_iters', 'seed', 'out_dir', 'pid', 'losses_train', 'losses_test',\n",
       "       'accs_train', 'accs_test', 'model_weights', 'comp_model_weights',\n",
       "       'explanation_divergence', 'divergence_comp', 'divergence', 'final_acc',\n",
       "       'final_cd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_both</th>\n",
       "      <th>sparse_signal</th>\n",
       "      <th>signal_strength</th>\n",
       "      <th>final_acc</th>\n",
       "      <th>final_cd</th>\n",
       "      <th>divergence</th>\n",
       "      <th>divergence_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>203.205975</td>\n",
       "      <td>0.055096</td>\n",
       "      <td>0.090846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>274.506503</td>\n",
       "      <td>0.060891</td>\n",
       "      <td>0.086863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>261.337331</td>\n",
       "      <td>0.062579</td>\n",
       "      <td>0.083246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>274.506503</td>\n",
       "      <td>0.067538</td>\n",
       "      <td>0.087556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>212.790776</td>\n",
       "      <td>0.075946</td>\n",
       "      <td>0.088427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>10.783402</td>\n",
       "      <td>0.177002</td>\n",
       "      <td>0.178456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5.554571</td>\n",
       "      <td>0.179307</td>\n",
       "      <td>0.198390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5.000549</td>\n",
       "      <td>0.237933</td>\n",
       "      <td>0.262403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.506135</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>1.017882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_both  sparse_signal  signal_strength  final_acc    final_cd  \\\n",
       "7       False           True             10.0       81.0  203.205975   \n",
       "0       False          False              1.0       80.0  274.506503   \n",
       "5       False          False             10.0       82.0  261.337331   \n",
       "8       False          False              1.0       80.0  274.506503   \n",
       "2       False           True              1.0       79.0  212.790776   \n",
       "6        True           True              1.0       79.0   10.783402   \n",
       "4        True           True             10.0       79.0    5.554571   \n",
       "3        True          False             10.0       77.0    5.000549   \n",
       "1        True          False              1.0       78.0    8.506135   \n",
       "\n",
       "   divergence  divergence_comp  \n",
       "7    0.055096         0.090846  \n",
       "0    0.060891         0.086863  \n",
       "5    0.062579         0.083246  \n",
       "8    0.067538         0.087556  \n",
       "2    0.075946         0.088427  \n",
       "6    0.177002         0.178456  \n",
       "4    0.179307         0.198390  \n",
       "3    0.237933         0.262403  \n",
       "1    0.866828         1.017882  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['divergence'] = divergence\n",
    "results[\"final_acc\"] = [x[-1] for x in results[\"accs_test\"]]\n",
    "results[\"final_cd\"] = [x[-1] for x in results[\"explanation_divergence\"]]\n",
    "results[['train_both','sparse_signal', 'signal_strength', 'final_acc', 'final_cd', 'divergence','divergence_comp' ]].sort_values(by=['divergence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(in1, in2):\n",
    "    a= (in1-in2)\n",
    "    b = (torch.log(in1) - torch.log(in2))\n",
    "\n",
    "    return (a*b).sum(dim=1).cpu().detach().numpy()\n",
    "def softmax(scores):\n",
    "    return torch.nn.functional.softmax(torch.stack((scores[0].view(-1),scores[1].view(-1)), 1), dim = 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def calc_expl_divergence(model1, model2, dataset):\n",
    "    ''' calculate explanation divergence between two models on the given dataset. Return'''\n",
    "    len_data = len(dev)\n",
    "    \n",
    "    expl_penalty = np.zeros((len_data))\n",
    "    is_correct = np.zeros((2, len_data))\n",
    "    num_reps = 5\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        cur_idx = 0\n",
    "        for dev_batch_idx, dev_batch in enumerate(dev_iter):\n",
    "            \n",
    "            batch_length, batch_num = dev_batch.text.shape\n",
    "            answer1 = model1(dev_batch)\n",
    "            answer2 = model2(dev_batch)\n",
    "            \n",
    "            for i in range(num_reps):\n",
    "                start = np.random.randint(batch_length-1)\n",
    "                stop = start + np.random.randint(batch_length-start)\n",
    "                expl_penalty[cur_idx:cur_idx+batch_num] +=(cd.cd_penalty(dev_batch, model1, model2, start, stop)).cpu().numpy()\n",
    "                \n",
    "            is_correct[0, cur_idx:cur_idx+batch_num]=(((torch.max(answer1, 1)[1].view(dev_batch.label.size()).data == dev_batch.label.data))).cpu().numpy()\n",
    "            is_correct[1, cur_idx:cur_idx+batch_num]=(((torch.max(answer2, 1)[1].view(dev_batch.label.size()).data == dev_batch.label.data))).cpu().numpy()\n",
    "            cur_idx+=batch_num\n",
    "        expl_penalty /=num_reps\n",
    "        one_wrong_idx = np.where(is_correct.mean(axis=0) ==0.5)[0]\n",
    "        both_correct_idx =np.where(is_correct.mean(axis=0) ==1)[0]\n",
    "        both_wrong_idx =np.where(is_correct.mean(axis=0) ==0)[0]\n",
    "        return expl_penalty.mean()#, expl_div[both_correct_idx].mean(), expl_div[one_wrong_idx].mean(), expl_div[both_wrong_idx].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_usage)",
   "language": "python",
   "name": "gpu_usage"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
