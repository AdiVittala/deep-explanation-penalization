{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "# compare how much divergence between model 1 trained and original model for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "sys.path.append('../../acd')\n",
    "sys.path.append('../../acd/visualization')\n",
    "sys.path.append('../../acd/acd/util')\n",
    "sys.path.append('../../acd/acd/scores')\n",
    "sys.path.append('../../acd/acd/agglomeration')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from model import LSTMSentiment\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isdir\n",
    "import viz_1d as viz\n",
    "import tiling_1d as tiling\n",
    "import agg_1d as agg\n",
    "import cd\n",
    "import score_funcs\n",
    "import dsets\n",
    "from dsets.sst import dset\n",
    "from dsets.sst.model import LSTMSentiment\n",
    "# check out how two models differ\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from tqdm import tqdm_notebook, tqdm \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_pkl = pickle.load(open('../../acd/dsets/sst/sst.pkl', 'rb'))\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_pkl = pickle.load(open('../../acd/dsets/sst/sst.pkl', 'rb'))\n",
    "np.random.seed(42)\n",
    "vector_cache = os.path.join(os.getcwd(), '../data/.vector_cache/input_vectors.pt')\n",
    "word_vectors ='glove.6B.300d'\n",
    "batch_size=  50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_folder = '../models/trained_models'\n",
    "init_model_folder = '../models/init_models'\n",
    "trained_list = os.listdir(trained_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.conda/envs/gpu_usage/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'model.LSTMSentiment' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "init_models = os.listdir(init_model_folder)\n",
    "init_model =torch.load(join(init_model_folder, init_models[0]))\n",
    "init_comp_model =torch.load(join(init_model_folder, init_models[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f8c7c770244698a67272b176c6433d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fnames = sorted([oj(trained_model_folder, fname) for fname in os.listdir(trained_model_folder)]) # filenames in the directory\n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in tqdm_notebook(fnames) ] \n",
    "results = pd.concat(results_list, axis=1).T.infer_objects() # pandas dataframe w/ hyperparams and weights stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "\n",
    "inputs = data.Field(lower= True)\n",
    "answers = data.Field(sequential=False, unk_token=None)\n",
    "\n",
    "train, dev, test = datasets.SST.splits(inputs, answers, fine_grained=False, train_subtrees=True,\n",
    "                                       filter_pred=lambda ex: ex.label != 'neutral')\n",
    "\n",
    "inputs.build_vocab(train, dev, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_vectors:\n",
    "    if os.path.isfile(vector_cache):\n",
    "        inputs.vocab.vectors = torch.load(vector_cache)\n",
    "    else:\n",
    "        inputs.vocab.load_vectors(word_vectors)\n",
    "        makedirs(os.path.dirname(vector_cache))\n",
    "        torch.save(inputs.vocab.vectors,vector_cache)\n",
    "answers.build_vocab(train)\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, dev, test), batch_size=batch_size, device=torch.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = deepcopy(init_model)\n",
    "trained_model.load_state_dict(results['model_weights'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08425198558273665\n"
     ]
    }
   ],
   "source": [
    "print(calc_expl_divergence(init_model, init_comp_model, dev)) #divergence between the two original models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f17f10089a04af9a4cfb1916ea7a167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.conda/envs/gpu_usage/lib/python3.6/site-packages/torch/nn/modules/rnn.py:179: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "divergence_comp = []\n",
    "trained_model = deepcopy(init_model)\n",
    "for i in tqdm_notebook(range(len(results))):\n",
    "    trained_model.load_state_dict(results['comp_model_weights'][i])\n",
    "    divergence_comp.append(calc_expl_divergence(trained_model, init_model, dev))\n",
    "results['divergence_comp'] = divergence_comp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ee098ffbad4f5aa055faa68f72157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "divergence = []\n",
    "trained_model = deepcopy(init_model)\n",
    "for i in tqdm_notebook(range(len(results))):\n",
    "    trained_model.load_state_dict(results['model_weights'][i])\n",
    "    divergence.append(calc_expl_divergence(trained_model, init_comp_model, dev))\n",
    "results['divergence'] = divergence    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_both</th>\n",
       "      <th>sparse_signal</th>\n",
       "      <th>signal_strength</th>\n",
       "      <th>final_acc</th>\n",
       "      <th>final_cd</th>\n",
       "      <th>divergence</th>\n",
       "      <th>divergence_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>203.205975</td>\n",
       "      <td>0.055893</td>\n",
       "      <td>0.079461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>261.337331</td>\n",
       "      <td>0.059441</td>\n",
       "      <td>0.084055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>226.873438</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>0.089416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>274.506503</td>\n",
       "      <td>0.065037</td>\n",
       "      <td>0.080025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>212.790776</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.086711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>245.139168</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>0.086350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5.554571</td>\n",
       "      <td>0.176107</td>\n",
       "      <td>0.199994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.093287</td>\n",
       "      <td>0.205032</td>\n",
       "      <td>0.220881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5.000549</td>\n",
       "      <td>0.244531</td>\n",
       "      <td>0.272252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.895252</td>\n",
       "      <td>0.251249</td>\n",
       "      <td>0.307977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.895252</td>\n",
       "      <td>0.254641</td>\n",
       "      <td>0.301387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.770723</td>\n",
       "      <td>0.581902</td>\n",
       "      <td>0.621743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.506135</td>\n",
       "      <td>0.814372</td>\n",
       "      <td>0.977774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_both  sparse_signal  signal_strength  final_acc    final_cd  \\\n",
       "9        False           True             10.0       81.0  203.205975   \n",
       "7        False          False             10.0       82.0  261.337331   \n",
       "12       False           True             10.0       81.0  226.873438   \n",
       "10       False          False              1.0       80.0  274.506503   \n",
       "3        False           True              1.0       79.0  212.790776   \n",
       "0        False           True              1.0       79.0  245.139168   \n",
       "5         True           True             10.0       79.0    5.554571   \n",
       "6         True           True             10.0       80.0    5.093287   \n",
       "4         True          False             10.0       77.0    5.000549   \n",
       "2         True           True              1.0       80.0    9.895252   \n",
       "11        True           True              1.0       80.0    9.895252   \n",
       "8         True          False              1.0       78.0   10.770723   \n",
       "1         True          False              1.0       78.0    8.506135   \n",
       "\n",
       "    divergence  divergence_comp  \n",
       "9     0.055893         0.079461  \n",
       "7     0.059441         0.084055  \n",
       "12    0.064658         0.089416  \n",
       "10    0.065037         0.080025  \n",
       "3     0.071519         0.086711  \n",
       "0     0.071601         0.086350  \n",
       "5     0.176107         0.199994  \n",
       "6     0.205032         0.220881  \n",
       "4     0.244531         0.272252  \n",
       "2     0.251249         0.307977  \n",
       "11    0.254641         0.301387  \n",
       "8     0.581902         0.621743  \n",
       "1     0.814372         0.977774  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['divergence'] = divergence\n",
    "results[\"final_acc\"] = [x[-1] for x in results[\"accs_test\"]]\n",
    "results[\"final_cd\"] = [x[-1] for x in results[\"explanation_divergence\"]]\n",
    "results[['train_both','sparse_signal', 'signal_strength', 'final_acc', 'final_cd', 'divergence','divergence_comp']].sort_values(by=['divergence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(in1, in2):\n",
    "    a= (in1-in2)\n",
    "    b = (torch.log(in1) - torch.log(in2))\n",
    "\n",
    "    return (a*b).sum(dim=1).cpu().detach().numpy()\n",
    "def softmax(scores):\n",
    "    return torch.nn.functional.softmax(torch.stack((scores[0].view(-1),scores[1].view(-1)), 1), dim = 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def calc_expl_divergence(model1, model2, dataset):\n",
    "    ''' calculate explanation divergence between two models on the given dataset. Return'''\n",
    "    len_data = len(dev)\n",
    "    \n",
    "    expl_penalty = np.zeros((len_data))\n",
    "    is_correct = np.zeros((2, len_data))\n",
    "    num_reps = 5\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        cur_idx = 0\n",
    "        for dev_batch_idx, dev_batch in enumerate(dev_iter):\n",
    "            \n",
    "            batch_length, batch_num = dev_batch.text.shape\n",
    "            answer1 = model1(dev_batch)\n",
    "            answer2 = model2(dev_batch)\n",
    "            \n",
    "            for i in range(num_reps):\n",
    "                start = np.random.randint(batch_length-1)\n",
    "                stop = start + np.random.randint(batch_length-start)\n",
    "                expl_penalty[cur_idx:cur_idx+batch_num] +=(cd.cd_penalty(dev_batch, model1, model2, start, stop)).cpu().numpy()\n",
    "                \n",
    "            is_correct[0, cur_idx:cur_idx+batch_num]=(((torch.max(answer1, 1)[1].view(dev_batch.label.size()).data == dev_batch.label.data))).cpu().numpy()\n",
    "            is_correct[1, cur_idx:cur_idx+batch_num]=(((torch.max(answer2, 1)[1].view(dev_batch.label.size()).data == dev_batch.label.data))).cpu().numpy()\n",
    "            cur_idx+=batch_num\n",
    "        expl_penalty /=num_reps\n",
    "        one_wrong_idx = np.where(is_correct.mean(axis=0) ==0.5)[0]\n",
    "        both_correct_idx =np.where(is_correct.mean(axis=0) ==1)[0]\n",
    "        both_wrong_idx =np.where(is_correct.mean(axis=0) ==0)[0]\n",
    "        return expl_penalty.mean()#, expl_div[both_correct_idx].mean(), expl_div[one_wrong_idx].mean(), expl_div[both_wrong_idx].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# form class to hold data\n",
    "class B:\n",
    "    text = torch.zeros(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-27c5931bafb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# prepare inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_from_str_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mscores_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mlabel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_all\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get predicted class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-27c5931bafb9>\u001b[0m in \u001b[0;36mbatch_from_str_list\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatch_from_str_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msst_pkl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stoi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "# base parameters\n",
    "sweep_dim = 1 # how large chunks of text should be considered (1 for words)\n",
    "method = 'cd' # build_up, break_down, cd\n",
    "percentile_include = 99.5 # keep this very high so we don't add too many words at once\n",
    "num_iters = 25 # maximum number of iterations (rarely reached)\n",
    "\n",
    "# text and label\n",
    "sentence = ['a', 'great', 'ensemble', 'cast', 'ca', 'n\\'t', 'lift', 'this', 'heartfelt', 'enterprise', 'out', 'of', 'the', 'familiar', '.'] # note this is a real example from the dataset\n",
    "# sentence = ['not', 'good', ',', 'not', 'bad', ',', 'just', 'okay'] # any text with words from this dataset can be interpreted\n",
    "label = 1 # 0 if positive 1 if negative\n",
    "\n",
    "\n",
    "def batch_from_str_list(s):\n",
    "    batch = B()\n",
    "    nums = np.expand_dims(np.array([sst_pkl['stoi'][x] for x in s]).transpose(), axis=1)\n",
    "    batch.text = torch.LongTensor(nums).to(device) #cuda()\n",
    "    return batch\n",
    "\n",
    "# prepare inputs\n",
    "batch = batch_from_str_list(sentence)\n",
    "scores_all = init_model(batch).data.cpu().numpy()[0] # predict\n",
    "label_pred = np.argmax(scores_all) # get predicted class\n",
    "\n",
    "# agglomerate\n",
    "lists = agg.agglomerate(init_model, batch, percentile_include, method, sweep_dim, # only works for sweep_dim = 1\n",
    "                    label_pred, num_iters=num_iters, device=device) # see agg_1d.agglomerate to understand what this dictionary contains\n",
    "lists = agg.collapse_tree(lists) # don't show redundant joins\n",
    "\n",
    "# visualize\n",
    "viz.word_heatmap(sentence, lists, label_pred, label, fontsize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_usage)",
   "language": "python",
   "name": "gpu_usage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
