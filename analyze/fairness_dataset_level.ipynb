{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../fit')\n",
    "\n",
    "from model import LSTMSentiment\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch\n",
    "import cd\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dset + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.conda/envs/gpu_usage/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'model.LSTMSentiment' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# data params\n",
    "vector_cache =  '../data/.vector_cache/input_vectors.pt'\n",
    "word_vectors ='glove.6B.300d'\n",
    "batch_size = 50\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# load dset\n",
    "inputs = data.Field(lower= True)\n",
    "answers = data.Field(sequential=False, unk_token=None)\n",
    "train, dev, test = datasets.SST.splits(inputs, answers, fine_grained=False, train_subtrees=False,\n",
    "                                       filter_pred=lambda ex: ex.label != 'neutral')\n",
    "inputs.build_vocab(train, dev, test)\n",
    "\n",
    "if os.path.isfile(vector_cache):\n",
    "    inputs.vocab.vectors = torch.load(vector_cache)\n",
    "else:\n",
    "    inputs.vocab.load_vectors(word_vectors)\n",
    "    os.makedirs(os.path.dirname(vector_cache), exist_ok=True)\n",
    "    torch.save(inputs.vocab.vectors, vector_cache)\n",
    "answers.build_vocab(train)\n",
    "\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, dev, test), batch_size=batch_size, device=torch.device(0),\n",
    "                sort_key=lambda x: len(x.text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "                         sort_within_batch=True,\n",
    "                shuffle =True,\n",
    "    sort = False,\n",
    "                         repeat=False)\n",
    "\n",
    "# load model\n",
    "model_path = \"../models/init_models\"\n",
    "model_list = os.listdir(model_path)\n",
    "model1 = torch.load(os.path.join(model_path, model_list[0]), map_location=torch.device(0)).eval()\n",
    "\n",
    "#model2 = torch.load(os.path.join(model_path, model_list[1]), map_location=torch.device(0)).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate cd word-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_length =0\n",
    "for i in range(len(train)):\n",
    "    tot_length +=len(train[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.29985549132948"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_length / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 50])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133555"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.776978417266186\n"
     ]
    }
   ],
   "source": [
    "tot_length =0\n",
    "it = train_iter\n",
    "num_batches = 0\n",
    "len_list = []\n",
    "for batch in (it):\n",
    "    tot_length +=batch.text.shape[0]\n",
    "    num_batches+=1\n",
    "    len_list.append(batch.text.shape[0])\n",
    "print(tot_length/num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c6e96d0373482c97be2193c91f8643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=139), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose hyperparams\n",
    "it = train_iter\n",
    "m = model1\n",
    "\n",
    "# what to store\n",
    "words = {}\n",
    "\n",
    "it.init_epoch()\n",
    "# check out how two models differ\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_dev_correct, dev_loss = 0, 0\n",
    "\n",
    "# remember batches are num_words x batch_size\n",
    "for batch in tqdm_notebook(it):\n",
    "    answer1 = m(batch)\n",
    "    num_words = batch.text.shape[0]\n",
    "    batch_size = batch.text.shape[1]\n",
    "    \n",
    "    for word_num in range(num_words-1):\n",
    "        word_per_batch = batch.text[word_num] # gets word at same place for all batches\n",
    "  \n",
    "        # get cd scores for each word\n",
    "        rel, _ = cd.cd_batch_text(batch, m, start=word_num, stop=word_num + 1)\n",
    "        rel = rel.softmax(dim=0) # 2 x batch_size\n",
    "        rel = rel[0] # only get positive class\n",
    "        \n",
    "        # actually get the words\n",
    "        for batch_num in range(word_per_batch.shape[0]):\n",
    "            word = inputs.vocab.itos[word_per_batch[batch_num]] \n",
    "          \n",
    "            score = rel[batch_num].item()\n",
    "            \n",
    "            # add to store\n",
    "            if not word in words:\n",
    "                words[word] = (1, score) # count, sum\n",
    "            else:\n",
    "                (count, running_sum) = words[word]\n",
    "                words[word] = (count + 1, running_sum + score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at fairness results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x = sorted(words.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [x for x in sorted_x if inputs.vocab.stoi[x[0]] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['word'] = words.keys()\n",
    "results['count'] = [words[word][0] for word in results['word']]\n",
    "results['sent'] = [words[word][1] / words[word][0] for word in results['word']]\n",
    "results = results.sort_values(by=['sent'], ascending=False)\n",
    "results.to_pickle('../results/word_fairness_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.read_pickle('../results/word_fairness_test.pkl')\n",
    "# r = r[r['sent'] <= .40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r[r['count'] >3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word  count      sent\n",
      "962  actor     12  0.555093 \n",
      "        word  count      sent\n",
      "68  actress      4  0.541827 \n",
      "\n",
      "      word  count      sent\n",
      "553  black      8  0.461766 \n",
      "        word  count     sent\n",
      "5584  white      2  0.52095 \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [word, count, sent]\n",
      "Index: [] \n",
      "        word  count      sent\n",
      "1136  video     15  0.476137 \n",
      "\n",
      "         word  count      sent\n",
      "1814  minutes     17  0.413592 \n",
      "       word  count     sent\n",
      "1354  hour      4  0.56039 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparisons = [('actor', 'actress'), ('black', 'white'), \n",
    "#                ('him', 'her'), ('young', 'old'), ('latino', 'asian'),\n",
    "               ('text', 'video'),\n",
    "              ('minutes', 'hour')]\n",
    "for (x, y) in comparisons:\n",
    "    print(r[r.word == x], '\\n', r[r.word == y], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
