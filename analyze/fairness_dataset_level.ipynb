{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../fit')\n",
    "\n",
    "from model import LSTMSentiment\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch\n",
    "import cd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dset + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "vector_cache =  '../data/.vector_cache/input_vectors.pt'\n",
    "word_vectors ='glove.6B.300d'\n",
    "batch_size = 50\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# load dset\n",
    "inputs = data.Field(lower= True)\n",
    "answers = data.Field(sequential=False, unk_token=None)\n",
    "train, dev, test = datasets.SST.splits(inputs, answers, fine_grained=False, train_subtrees=True,\n",
    "                                       filter_pred=lambda ex: ex.label != 'neutral')\n",
    "inputs.build_vocab(train, dev, test)\n",
    "\n",
    "if os.path.isfile(vector_cache):\n",
    "    inputs.vocab.vectors = torch.load(vector_cache)\n",
    "else:\n",
    "    inputs.vocab.load_vectors(word_vectors)\n",
    "    os.makedirs(os.path.dirname(vector_cache), exist_ok=True)\n",
    "    torch.save(inputs.vocab.vectors,vector_cache)\n",
    "answers.build_vocab(train)\n",
    "\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, dev, test), batch_size=batch_size, device=torch.device(0))\n",
    "\n",
    "# load model\n",
    "model_path = \"../models/init_models\"\n",
    "model_list = os.listdir(model_path)\n",
    "model1 = torch.load(os.path.join(model_path, model_list[0]), map_location=torch.device(0)).eval()\n",
    "\n",
    "model2 = torch.load(os.path.join(model_path, model_list[1]), map_location=torch.device(0)).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate cd word-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose hyperparams\n",
    "it = dev_iter\n",
    "m = model1\n",
    "\n",
    "it.init_epoch()\n",
    "# check out how two models differ\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_dev_correct, dev_loss = 0, 0\n",
    "for dev_batch_idx, dev_batch in enumerate(it):\n",
    "    answer1 = m(dev_batch)\n",
    "    batch_length = dev_batch.text.shape[0]\n",
    "    batch_num = dev_batch.text.shape[1]\n",
    "\n",
    "    start = np.random.randint(batch_length-1)\n",
    "    stop = start + np.random.randint(batch_length-start)\n",
    "    rel, _ =cd.cd_batch_text(dev_batch, m, start, stop)\n",
    "    print(rel)\n",
    "#     n_dev_correct += (((torch.max(answer2, 1)[1].view(dev_batch.label.size()).data == dev_batch.label.data))).sum()\n",
    "#     dev_loss = criterion(answer2, dev_batch.label)\n",
    "# dev_acc = 100. * n_dev_correct / len(dev)\n",
    "# print(dev_acc.item(), dev_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
