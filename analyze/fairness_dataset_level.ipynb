{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../fit')\n",
    "\n",
    "from model import LSTMSentiment\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch\n",
    "import cd\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dset + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.conda/envs/gpu_usage/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'model.LSTMSentiment' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# data params\n",
    "vector_cache =  '../data/.vector_cache/input_vectors.pt'\n",
    "word_vectors ='glove.6B.300d'\n",
    "batch_size = 50\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# load dset\n",
    "inputs = data.Field(lower= True)\n",
    "answers = data.Field(sequential=False, unk_token=None)\n",
    "train, dev, test = datasets.SST.splits(inputs, answers, fine_grained=False, train_subtrees=True,\n",
    "                                       filter_pred=lambda ex: ex.label != 'neutral')\n",
    "inputs.build_vocab(train, dev, test)\n",
    "\n",
    "if os.path.isfile(vector_cache):\n",
    "    inputs.vocab.vectors = torch.load(vector_cache)\n",
    "else:\n",
    "    inputs.vocab.load_vectors(word_vectors)\n",
    "    os.makedirs(os.path.dirname(vector_cache), exist_ok=True)\n",
    "    torch.save(inputs.vocab.vectors, vector_cache)\n",
    "answers.build_vocab(train)\n",
    "\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, dev, test), batch_size=batch_size, device=torch.device(0))\n",
    "\n",
    "# load model\n",
    "model_path = \"../models/init_models\"\n",
    "model_list = os.listdir(model_path)\n",
    "model1 = torch.load(os.path.join(model_path, model_list[0]), map_location=torch.device(0)).eval()\n",
    "\n",
    "model2 = torch.load(os.path.join(model_path, model_list[1]), map_location=torch.device(0)).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate cd word-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.vocab.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [01:18<00:00,  7.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# choose hyperparams\n",
    "it = test_iter\n",
    "m = model1\n",
    "\n",
    "# what to store\n",
    "words = {}\n",
    "\n",
    "it.init_epoch()\n",
    "# check out how two models differ\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_dev_correct, dev_loss = 0, 0\n",
    "\n",
    "# remember batches are num_words x batch_size\n",
    "for batch in tqdm(it):\n",
    "    answer1 = m(batch)\n",
    "    num_words = batch.text.shape[0]\n",
    "    batch_size = batch.text.shape[1]\n",
    "    \n",
    "    for word_num in range(num_words):\n",
    "        word_per_batch = batch.text[word_num] # gets word at same place for all batches\n",
    "        \n",
    "        # get cd scores for each word\n",
    "        rel, _ = cd.cd_batch_text(batch, m, start=word_num, stop=word_num + 1)\n",
    "        rel = rel.softmax(dim=0) # 2 x batch_size\n",
    "        rel = rel[0] # only get positive class\n",
    "        \n",
    "        # actually get the words\n",
    "        for batch_num in range(word_per_batch.shape[0]):\n",
    "            word = inputs.vocab.itos[word_per_batch[batch_num]]\n",
    "            score = rel[batch_num].item()\n",
    "            \n",
    "            # add to store\n",
    "            if not word in words:\n",
    "                words[word] = (1, score) # count, sum\n",
    "            else:\n",
    "                (count, running_sum) = words[word]\n",
    "                words[word] = (count + 1, running_sum + score)\n",
    "#     n_dev_correct += (((torch.max(answer2, 1)[1].view(dev_batch.label.size()).data == dev_batch.label.data))).sum()\n",
    "#     dev_loss = criterion(answer2, dev_batch.label)\n",
    "# dev_acc = 100. * n_dev_correct / len(dev)\n",
    "# print(dev_acc.item(), dev_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at fairness results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['word'] = words.keys()\n",
    "results['count'] = [words[word][0] for word in results['word']]\n",
    "results['sent'] = [words[word][1] / words[word][0] for word in results['word']]\n",
    "results = results.sort_values(by=['sent'], ascending=False)\n",
    "results.to_pickle('results/word_fairness_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>5</td>\n",
       "      <td>0.814058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>7</td>\n",
       "      <td>0.792790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>mesmerizing</td>\n",
       "      <td>5</td>\n",
       "      <td>0.791960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>enjoy</td>\n",
       "      <td>11</td>\n",
       "      <td>0.786107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>honesty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.783679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>pleasure</td>\n",
       "      <td>8</td>\n",
       "      <td>0.781759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>intelligent</td>\n",
       "      <td>13</td>\n",
       "      <td>0.768969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>creative</td>\n",
       "      <td>5</td>\n",
       "      <td>0.766074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>excellent</td>\n",
       "      <td>7</td>\n",
       "      <td>0.765148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>polished</td>\n",
       "      <td>6</td>\n",
       "      <td>0.765092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>natural</td>\n",
       "      <td>5</td>\n",
       "      <td>0.763966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>entertain</td>\n",
       "      <td>5</td>\n",
       "      <td>0.758498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>10</td>\n",
       "      <td>0.755145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>honest</td>\n",
       "      <td>10</td>\n",
       "      <td>0.747792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>pleasant</td>\n",
       "      <td>5</td>\n",
       "      <td>0.739168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>career</td>\n",
       "      <td>7</td>\n",
       "      <td>0.735116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>bring</td>\n",
       "      <td>5</td>\n",
       "      <td>0.728188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>genuine</td>\n",
       "      <td>8</td>\n",
       "      <td>0.725560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>refreshingly</td>\n",
       "      <td>7</td>\n",
       "      <td>0.724947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>sincere</td>\n",
       "      <td>5</td>\n",
       "      <td>0.721354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>worth</td>\n",
       "      <td>15</td>\n",
       "      <td>0.720347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>welcome</td>\n",
       "      <td>5</td>\n",
       "      <td>0.719666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>daring</td>\n",
       "      <td>7</td>\n",
       "      <td>0.716230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>satisfying</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>fun</td>\n",
       "      <td>27</td>\n",
       "      <td>0.710059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>modern</td>\n",
       "      <td>6</td>\n",
       "      <td>0.701917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>good</td>\n",
       "      <td>54</td>\n",
       "      <td>0.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>charm</td>\n",
       "      <td>16</td>\n",
       "      <td>0.701419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>thoughtful</td>\n",
       "      <td>6</td>\n",
       "      <td>0.699416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>surprisingly</td>\n",
       "      <td>7</td>\n",
       "      <td>0.698357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>low</td>\n",
       "      <td>5</td>\n",
       "      <td>0.353882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>mess</td>\n",
       "      <td>13</td>\n",
       "      <td>0.353203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>wo</td>\n",
       "      <td>6</td>\n",
       "      <td>0.352432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>monster</td>\n",
       "      <td>6</td>\n",
       "      <td>0.351920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>n't</td>\n",
       "      <td>134</td>\n",
       "      <td>0.351855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nothing</td>\n",
       "      <td>24</td>\n",
       "      <td>0.351694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>quickly</td>\n",
       "      <td>6</td>\n",
       "      <td>0.350743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>cynical</td>\n",
       "      <td>5</td>\n",
       "      <td>0.350089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>did</td>\n",
       "      <td>15</td>\n",
       "      <td>0.344622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>pretentious</td>\n",
       "      <td>9</td>\n",
       "      <td>0.344038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>joke</td>\n",
       "      <td>6</td>\n",
       "      <td>0.342196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>lacks</td>\n",
       "      <td>10</td>\n",
       "      <td>0.337294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>boring</td>\n",
       "      <td>14</td>\n",
       "      <td>0.335516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>routine</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>fails</td>\n",
       "      <td>9</td>\n",
       "      <td>0.332711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>else</td>\n",
       "      <td>8</td>\n",
       "      <td>0.324848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>lack</td>\n",
       "      <td>15</td>\n",
       "      <td>0.321767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>dumb</td>\n",
       "      <td>10</td>\n",
       "      <td>0.320841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>dull</td>\n",
       "      <td>13</td>\n",
       "      <td>0.316073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>bad</td>\n",
       "      <td>43</td>\n",
       "      <td>0.310998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>waste</td>\n",
       "      <td>5</td>\n",
       "      <td>0.292127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>weak</td>\n",
       "      <td>6</td>\n",
       "      <td>0.291125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>nonsense</td>\n",
       "      <td>7</td>\n",
       "      <td>0.291002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>stupid</td>\n",
       "      <td>5</td>\n",
       "      <td>0.277147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>gone</td>\n",
       "      <td>7</td>\n",
       "      <td>0.275324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>ugly</td>\n",
       "      <td>5</td>\n",
       "      <td>0.266628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>worst</td>\n",
       "      <td>7</td>\n",
       "      <td>0.256231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>lame</td>\n",
       "      <td>5</td>\n",
       "      <td>0.230634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ridiculous</td>\n",
       "      <td>5</td>\n",
       "      <td>0.179618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>?</td>\n",
       "      <td>24</td>\n",
       "      <td>0.168726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>787 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  count      sent\n",
       "31       brilliant      5  0.814058\n",
       "55       wonderful      7  0.792790\n",
       "550    mesmerizing      5  0.791960\n",
       "125          enjoy     11  0.786107\n",
       "1542       honesty      5  0.783679\n",
       "1311      pleasure      8  0.781759\n",
       "210    intelligent     13  0.768969\n",
       "3708      creative      5  0.766074\n",
       "10       excellent      7  0.765148\n",
       "796       polished      6  0.765092\n",
       "876        natural      5  0.763966\n",
       "94       entertain      5  0.758498\n",
       "693      enjoyable     10  0.755145\n",
       "1654        honest     10  0.747792\n",
       "53        pleasant      5  0.739168\n",
       "752         career      7  0.735116\n",
       "798          bring      5  0.728188\n",
       "126        genuine      8  0.725560\n",
       "175   refreshingly      7  0.724947\n",
       "851        sincere      5  0.721354\n",
       "50           worth     15  0.720347\n",
       "2703       welcome      5  0.719666\n",
       "602         daring      7  0.716230\n",
       "1845    satisfying      5  0.714957\n",
       "103            fun     27  0.710059\n",
       "1774        modern      6  0.701917\n",
       "32            good     54  0.701900\n",
       "996          charm     16  0.701419\n",
       "152     thoughtful      6  0.699416\n",
       "205   surprisingly      7  0.698357\n",
       "...            ...    ...       ...\n",
       "991            low      5  0.353882\n",
       "105           mess     13  0.353203\n",
       "2316            wo      6  0.352432\n",
       "1145       monster      6  0.351920\n",
       "54             n't    134  0.351855\n",
       "7          nothing     24  0.351694\n",
       "961        quickly      6  0.350743\n",
       "1007       cynical      5  0.350089\n",
       "75             did     15  0.344622\n",
       "434    pretentious      9  0.344038\n",
       "1761          joke      6  0.342196\n",
       "215          lacks     10  0.337294\n",
       "8           boring     14  0.335516\n",
       "405        routine      6  0.333563\n",
       "343          fails      9  0.332711\n",
       "192           else      8  0.324848\n",
       "1401          lack     15  0.321767\n",
       "65            dumb     10  0.320841\n",
       "185           dull     13  0.316073\n",
       "78             bad     43  0.310998\n",
       "168          waste      5  0.292127\n",
       "1172          weak      6  0.291125\n",
       "2355      nonsense      7  0.291002\n",
       "237         stupid      5  0.277147\n",
       "567           gone      7  0.275324\n",
       "2860          ugly      5  0.266628\n",
       "1002         worst      7  0.256231\n",
       "147           lame      5  0.230634\n",
       "33      ridiculous      5  0.179618\n",
       "123              ?     24  0.168726\n",
       "\n",
       "[787 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.read_pickle('results/word_fairness_test.pkl')\n",
    "r[r['count'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word  count      sent\n",
      "962  actor     12  0.555093 \n",
      "        word  count      sent\n",
      "68  actress      4  0.541827 \n",
      "\n",
      "      word  count      sent\n",
      "553  black      8  0.461766 \n",
      "        word  count     sent\n",
      "5584  white      2  0.52095 \n",
      "\n",
      "    word  count      sent\n",
      "915  him      5  0.493404 \n",
      "     word  count      sent\n",
      "292  her     38  0.614049 \n",
      "\n",
      "       word  count      sent\n",
      "1840  young      8  0.602673 \n",
      "     word  count      sent\n",
      "618  old     16  0.430794 \n",
      "\n",
      "        word  count      sent\n",
      "5783  latino      1  0.609252 \n",
      "        word  count      sent\n",
      "1794  asian      2  0.637687 \n",
      "\n",
      "        word  count      sent\n",
      "920  romance     11  0.650436 \n",
      "        word  count      sent\n",
      "116  comedy     62  0.614354 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparisons = [('actor', 'actress'), ('black', 'white'), \n",
    "               ('him', 'her'), ('young', 'old'), ('latino', 'asian'),\n",
    "               ('romance', 'comedy')]\n",
    "for (x, y) in comparisons:\n",
    "    print(r[r.word == x], '\\n', r[r.word == y], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
