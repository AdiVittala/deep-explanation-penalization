{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../fit')\n",
    "\n",
    "from model import LSTMSentiment\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch\n",
    "import cd\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dset + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.local/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'model.LSTMSentiment' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/lauri/.local/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/lauri/.local/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/lauri/.local/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# data params\n",
    "vector_cache =  '../data/.vector_cache/input_vectors.pt'\n",
    "word_vectors ='glove.6B.300d'\n",
    "batch_size = 50\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# load dset\n",
    "inputs = data.Field(lower= True)\n",
    "answers = data.Field(sequential=False, unk_token=None)\n",
    "train, dev, test = datasets.SST.splits(inputs, answers, fine_grained=False, train_subtrees=False,\n",
    "                                       filter_pred=lambda ex: ex.label != 'neutral')\n",
    "inputs.build_vocab(train, dev, test)\n",
    "\n",
    "if os.path.isfile(vector_cache):\n",
    "    inputs.vocab.vectors = torch.load(vector_cache)\n",
    "else:\n",
    "    inputs.vocab.load_vectors(word_vectors)\n",
    "    os.makedirs(os.path.dirname(vector_cache), exist_ok=True)\n",
    "    torch.save(inputs.vocab.vectors, vector_cache)\n",
    "answers.build_vocab(train)\n",
    "\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, dev, test), batch_size=batch_size, device=torch.device(0),\n",
    "                sort_key=lambda x: len(x.text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "                         sort_within_batch=True,\n",
    "                shuffle =True,\n",
    "    sort = False,\n",
    "                         repeat=False)\n",
    "\n",
    "# load model\n",
    "model_path = \"../models/init_models\"\n",
    "model_list = os.listdir(model_path)\n",
    "model1 = torch.load(os.path.join(model_path, model_list[0]), map_location=torch.device(0)).eval()\n",
    "\n",
    "#model2 = torch.load(os.path.join(model_path, model_list[1]), map_location=torch.device(0)).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate cd word-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_length =0\n",
    "for i in range(len(train)):\n",
    "    tot_length +=len(train[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff1d45c93bc443fb0aecfca699380a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=139), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# choose hyperparams\n",
    "it = train_iter\n",
    "m = model1\n",
    "\n",
    "# what to store\n",
    "words = {}\n",
    "\n",
    "it.init_epoch()\n",
    "# check out how two models differ\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_dev_correct, dev_loss = 0, 0\n",
    "\n",
    "# remember batches are num_words x batch_size\n",
    "for batch in tqdm_notebook(it):\n",
    "    answer1 = m(batch)\n",
    "    num_words = batch.text.shape[0]\n",
    "    batch_size = batch.text.shape[1]\n",
    "    \n",
    "    for word_num in range(num_words-1):\n",
    "        word_per_batch = batch.text[word_num] # gets word at same place for all batches\n",
    "  \n",
    "        # get cd scores for each word\n",
    "        rel, _ = cd.cd_batch_text(batch, m, start=word_num, stop=word_num + 1)\n",
    "        rel = rel.softmax(dim=0) # 2 x batch_size\n",
    "        rel = rel[0] # only get positive class\n",
    "        \n",
    "        # actually get the words\n",
    "        for batch_num in range(word_per_batch.shape[0]):\n",
    "            word = inputs.vocab.itos[word_per_batch[batch_num]] \n",
    "          \n",
    "            score = rel[batch_num].item()\n",
    "            \n",
    "            # add to store\n",
    "            if not word in words:\n",
    "                words[word] = (1, score) # count, sum\n",
    "            else:\n",
    "                (count, running_sum) = words[word]\n",
    "                words[word] = (count + 1, running_sum + score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at fairness results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e8d29bd14461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_x = sorted(words.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-adf6b481db4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_x\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_x' is not defined"
     ]
    }
   ],
   "source": [
    "test = [x for x in sorted_x if inputs.vocab.stoi[x[0]] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4b2b1374d98f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['word'] = words.keys()\n",
    "results['count'] = [words[word][0] for word in results['word']]\n",
    "results['sent'] = [words[word][1] / words[word][0] for word in results['word']]\n",
    "results = results.sort_values(by=['sent'], ascending=False)\n",
    "results.to_pickle('../results/word_fairness_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../results/word_fairness_test.pkl')\n",
    "# r = r[r['sent'] <= .40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>5954</td>\n",
       "      <td>0.528480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>,</td>\n",
       "      <td>5883</td>\n",
       "      <td>0.526845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.539533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>and</td>\n",
       "      <td>3831</td>\n",
       "      <td>0.510247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>of</td>\n",
       "      <td>3631</td>\n",
       "      <td>0.515243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>to</td>\n",
       "      <td>2438</td>\n",
       "      <td>0.539548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>is</td>\n",
       "      <td>2095</td>\n",
       "      <td>0.512990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>'s</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.513493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it</td>\n",
       "      <td>1947</td>\n",
       "      <td>0.520693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>.</td>\n",
       "      <td>1808</td>\n",
       "      <td>0.528304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>that</td>\n",
       "      <td>1612</td>\n",
       "      <td>0.526323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>in</td>\n",
       "      <td>1556</td>\n",
       "      <td>0.558175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>as</td>\n",
       "      <td>1074</td>\n",
       "      <td>0.517244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>film</td>\n",
       "      <td>955</td>\n",
       "      <td>0.536431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>with</td>\n",
       "      <td>953</td>\n",
       "      <td>0.545331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>but</td>\n",
       "      <td>853</td>\n",
       "      <td>0.538623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this</td>\n",
       "      <td>830</td>\n",
       "      <td>0.522726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>an</td>\n",
       "      <td>825</td>\n",
       "      <td>0.527612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>for</td>\n",
       "      <td>812</td>\n",
       "      <td>0.539070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>movie</td>\n",
       "      <td>807</td>\n",
       "      <td>0.530219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>its</td>\n",
       "      <td>767</td>\n",
       "      <td>0.501731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you</td>\n",
       "      <td>665</td>\n",
       "      <td>0.565760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>545</td>\n",
       "      <td>0.560124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>be</td>\n",
       "      <td>537</td>\n",
       "      <td>0.545110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>n't</td>\n",
       "      <td>535</td>\n",
       "      <td>0.356428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>on</td>\n",
       "      <td>521</td>\n",
       "      <td>0.375086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>...</td>\n",
       "      <td>473</td>\n",
       "      <td>0.530594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>by</td>\n",
       "      <td>454</td>\n",
       "      <td>0.516921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>one</td>\n",
       "      <td>446</td>\n",
       "      <td>0.536058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>not</td>\n",
       "      <td>439</td>\n",
       "      <td>0.527012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10456</th>\n",
       "      <td>collect</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>aid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6760</th>\n",
       "      <td>moratorium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14360</th>\n",
       "      <td>courtroom</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>broader</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13292</th>\n",
       "      <td>meara</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11354</th>\n",
       "      <td>restage</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12153</th>\n",
       "      <td>geneva</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021</th>\n",
       "      <td>gymnastics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7285</th>\n",
       "      <td>glow</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>melancholia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13927</th>\n",
       "      <td>exxon</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13017</th>\n",
       "      <td>verdu</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11943</th>\n",
       "      <td>marilyn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14142</th>\n",
       "      <td>clouds</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>land-based</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13588</th>\n",
       "      <td>vega</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9850</th>\n",
       "      <td>yours</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6762</th>\n",
       "      <td>gidget</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14479</th>\n",
       "      <td>acclaim</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13926</th>\n",
       "      <td>provocateur</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>trim</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9147</th>\n",
       "      <td>tries-so-hard-to-be-cool</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>jaw</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12894</th>\n",
       "      <td>lensing</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>admitting</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13764</th>\n",
       "      <td>carnivore</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8486</th>\n",
       "      <td>coburn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>big-fisted</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13087</th>\n",
       "      <td>party-hearty</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14812 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           word  count      sent\n",
       "2                           the   5954  0.528480\n",
       "58                            ,   5883  0.526845\n",
       "0                             a   4361  0.539533\n",
       "98                          and   3831  0.510247\n",
       "47                           of   3631  0.515243\n",
       "99                           to   2438  0.539548\n",
       "37                           is   2095  0.512990\n",
       "32                           's   2025  0.513493\n",
       "1                            it   1947  0.520693\n",
       "1184                          .   1808  0.528304\n",
       "13                         that   1612  0.526323\n",
       "23                           in   1556  0.558175\n",
       "22                           as   1074  0.517244\n",
       "36                         film    955  0.536431\n",
       "219                        with    953  0.545331\n",
       "7                           but    853  0.538623\n",
       "4                          this    830  0.522726\n",
       "5                            an    825  0.527612\n",
       "19                          for    812  0.539070\n",
       "64                        movie    807  0.530219\n",
       "48                          its    767  0.501731\n",
       "3                           you    665  0.565760\n",
       "4466                      <pad>    545  0.560124\n",
       "68                           be    537  0.545110\n",
       "76                          n't    535  0.356428\n",
       "140                          on    521  0.375086\n",
       "12                          ...    473  0.530594\n",
       "276                          by    454  0.516921\n",
       "455                         one    446  0.536058\n",
       "6                           not    439  0.527012\n",
       "...                         ...    ...       ...\n",
       "10456                   collect      1  0.501957\n",
       "6107                        aid      1  0.502089\n",
       "6760                 moratorium      1  0.501956\n",
       "14360                 courtroom      1  0.501956\n",
       "10086                   broader      1  0.501952\n",
       "13292                     meara      1  0.501948\n",
       "11354                   restage      1  0.501934\n",
       "12153                    geneva      1  0.501934\n",
       "8021                 gymnastics      1  0.501924\n",
       "7285                       glow      1  0.502082\n",
       "14165               melancholia      1  0.502091\n",
       "13927                     exxon      1  0.502231\n",
       "13017                     verdu      1  0.502156\n",
       "11943                   marilyn      1  0.502214\n",
       "14142                    clouds      1  0.502213\n",
       "4778                 land-based      1  0.502208\n",
       "13588                      vega      1  0.502204\n",
       "9850                      yours      1  0.502181\n",
       "6762                     gidget      1  0.502177\n",
       "14479                   acclaim      1  0.502161\n",
       "13926               provocateur      1  0.502155\n",
       "7482                       trim      1  0.502107\n",
       "9147   tries-so-hard-to-be-cool      1  0.502146\n",
       "8206                        jaw      1  0.502142\n",
       "12894                   lensing      1  0.502135\n",
       "4691                  admitting      1  0.502131\n",
       "13764                 carnivore      1  0.502128\n",
       "8486                     coburn      1  0.502116\n",
       "10802                big-fisted      1  0.502112\n",
       "13087              party-hearty      1  0.006191\n",
       "\n",
       "[14812 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = ['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word  count      sent\n",
      "1128  actor     26  0.334335 \n",
      "          word  count      sent\n",
      "4705  actress     16  0.588069 \n",
      "\n",
      "    word  count      sent\n",
      "482   he    163  0.623058 \n",
      "      word  count      sent\n",
      "1483  she     55  0.600758 \n",
      "\n",
      "    word  count      sent\n",
      "353  him     45  0.486916 \n",
      "      word  count      sent\n",
      "1161  her    109  0.529266 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparisons = [('actor', 'actress'), ('he', 'she'),('him', 'her'), ]\n",
    "for (x, y) in comparisons:\n",
    "    print(r[r.word == x], '\\n', r[r.word == y], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6920"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05057803468208093"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "350/6920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
