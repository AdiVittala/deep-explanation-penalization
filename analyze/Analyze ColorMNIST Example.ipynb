{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from os.path import join as oj\n",
    "import torch.utils.data as utils\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.conda/envs/gpu_usage/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../results_for_export\"\n",
    "trained_model_folder = '../MNIST_results/'\n",
    "fnames = sorted([oj(trained_model_folder, fname) for fname in os.listdir(trained_model_folder) if 'block' not in fname]) \n",
    "# other models were trained badly\n",
    "\n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in (fnames)] \n",
    "results = pd.concat(results_list, axis=1).T.infer_objects() \n",
    "results['final_acc'] = [max(x) for x in results['accs_test']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[results.method != 'CD_Omvendt' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['final_acc'] = [x[-1] for x in results['accs_test']] \n",
    "results['final_acc_train'] = [max(x) for x in results['accs_train']]\n",
    "\n",
    "\n",
    "results['final_cd'] = [x[-1] for x in results['cd']]\n",
    "results['final_test_loss'] = [x[-1] for x in results['losses_test']]\n",
    "\n",
    "\n",
    "results['final_train_loss'] = [min(x) for x in results['losses_train']]\n",
    "results['acc_color'] = [0 for x in results['accs_train']]\n",
    "if not 'method' in list(results.columns):\n",
    "    results['method'] = ['CD' for x in results['accs_train']]\n",
    "if not 'method' in list(results.columns):\n",
    "    results['method'] = ['CD' for x in results['accs_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.dropna()\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "results_save = results[['regularizer_rate','final_acc','final_acc_train','final_test_loss', 'acc_color','final_cd', 'method']].sort_values(by = ['regularizer_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th>final_acc</th>\n",
       "      <th>final_acc_train</th>\n",
       "      <th>final_test_loss</th>\n",
       "      <th>acc_color</th>\n",
       "      <th>final_cd</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>73.79</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.52</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.592</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>65.15</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.1</td>\n",
       "      <td>62.44</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.744</td>\n",
       "      <td>0</td>\n",
       "      <td>1.090e-03</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.1</td>\n",
       "      <td>61.78</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.275</td>\n",
       "      <td>0</td>\n",
       "      <td>7.152e-06</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.1</td>\n",
       "      <td>70.14</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.592</td>\n",
       "      <td>0</td>\n",
       "      <td>7.907e-04</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1</td>\n",
       "      <td>61.82</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.871</td>\n",
       "      <td>0</td>\n",
       "      <td>2.807e-04</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>97.89</td>\n",
       "      <td>99.609</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0</td>\n",
       "      <td>6.208e-02</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.1</td>\n",
       "      <td>62.82</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.118</td>\n",
       "      <td>0</td>\n",
       "      <td>2.175e-06</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>98.44</td>\n",
       "      <td>99.609</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0</td>\n",
       "      <td>6.688e-02</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1</td>\n",
       "      <td>59.98</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.181</td>\n",
       "      <td>0</td>\n",
       "      <td>5.214e-05</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>74.25</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.169</td>\n",
       "      <td>0</td>\n",
       "      <td>1.563e-05</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.92</td>\n",
       "      <td>100.000</td>\n",
       "      <td>3.848</td>\n",
       "      <td>0</td>\n",
       "      <td>3.185e-05</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>71.23</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.106</td>\n",
       "      <td>0</td>\n",
       "      <td>5.303e-05</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.0</td>\n",
       "      <td>69.65</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.938</td>\n",
       "      <td>0</td>\n",
       "      <td>7.408e-05</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.728</td>\n",
       "      <td>0</td>\n",
       "      <td>1.554e-05</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.07</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.941e-04</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10.0</td>\n",
       "      <td>97.75</td>\n",
       "      <td>99.219</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "      <td>4.846e-03</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>85.21</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0</td>\n",
       "      <td>2.714e-06</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.0</td>\n",
       "      <td>57.57</td>\n",
       "      <td>100.000</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0</td>\n",
       "      <td>2.035e-05</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.0</td>\n",
       "      <td>74.62</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.452</td>\n",
       "      <td>0</td>\n",
       "      <td>2.711e-05</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.0</td>\n",
       "      <td>69.79</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.692</td>\n",
       "      <td>0</td>\n",
       "      <td>1.374e-05</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>10.0</td>\n",
       "      <td>54.21</td>\n",
       "      <td>100.000</td>\n",
       "      <td>3.929</td>\n",
       "      <td>0</td>\n",
       "      <td>2.467e-06</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.0</td>\n",
       "      <td>88.02</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0</td>\n",
       "      <td>3.077e-06</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10.0</td>\n",
       "      <td>56.87</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.873</td>\n",
       "      <td>0</td>\n",
       "      <td>2.725e-05</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>10.0</td>\n",
       "      <td>73.21</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.269</td>\n",
       "      <td>0</td>\n",
       "      <td>2.281e-06</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>72.70</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.713</td>\n",
       "      <td>0</td>\n",
       "      <td>1.081e-05</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>10.0</td>\n",
       "      <td>98.04</td>\n",
       "      <td>99.219</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0</td>\n",
       "      <td>3.728e-03</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>97.85</td>\n",
       "      <td>99.219</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0</td>\n",
       "      <td>5.343e-03</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100.0</td>\n",
       "      <td>74.54</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.207</td>\n",
       "      <td>0</td>\n",
       "      <td>2.390e-06</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>98.34</td>\n",
       "      <td>99.219</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0</td>\n",
       "      <td>4.050e-08</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>98.06</td>\n",
       "      <td>99.609</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0</td>\n",
       "      <td>5.580e-08</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>97.66</td>\n",
       "      <td>99.609</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "      <td>1.146e-08</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>42.188</td>\n",
       "      <td>3.793</td>\n",
       "      <td>0</td>\n",
       "      <td>5.215e-04</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>99.01</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0</td>\n",
       "      <td>5.458e-07</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>98.80</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0</td>\n",
       "      <td>1.359e-06</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>97.40</td>\n",
       "      <td>99.219</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184e-14</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>97.40</td>\n",
       "      <td>98.828</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0</td>\n",
       "      <td>2.441e-14</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>42.188</td>\n",
       "      <td>9.169</td>\n",
       "      <td>0</td>\n",
       "      <td>3.153e-05</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>97.32</td>\n",
       "      <td>98.828</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>1.354e-13</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>97.15</td>\n",
       "      <td>98.828</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0</td>\n",
       "      <td>6.419e-13</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>97.58</td>\n",
       "      <td>98.828</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0</td>\n",
       "      <td>1.846e-14</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>97.62</td>\n",
       "      <td>98.828</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0</td>\n",
       "      <td>5.007e-14</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>99.20</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>1.090e-08</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>42.188</td>\n",
       "      <td>9.776</td>\n",
       "      <td>0</td>\n",
       "      <td>6.755e-05</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>42.188</td>\n",
       "      <td>10.729</td>\n",
       "      <td>0</td>\n",
       "      <td>4.548e-05</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>99.15</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>1.876e-08</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>99.25</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0</td>\n",
       "      <td>2.965e-08</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>42.188</td>\n",
       "      <td>15.527</td>\n",
       "      <td>0</td>\n",
       "      <td>7.296e-06</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>96.09</td>\n",
       "      <td>97.266</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>2.012e-17</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>96.42</td>\n",
       "      <td>97.656</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0</td>\n",
       "      <td>4.018e-16</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>42.188</td>\n",
       "      <td>15.302</td>\n",
       "      <td>0</td>\n",
       "      <td>4.012e-06</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>99.23</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>8.960e-10</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>96.06</td>\n",
       "      <td>97.656</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0</td>\n",
       "      <td>7.081e-20</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>99.17</td>\n",
       "      <td>99.609</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0</td>\n",
       "      <td>1.205e-08</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>42.188</td>\n",
       "      <td>15.954</td>\n",
       "      <td>0</td>\n",
       "      <td>7.172e-06</td>\n",
       "      <td>ExpectedGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>96.45</td>\n",
       "      <td>97.656</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0</td>\n",
       "      <td>1.313e-18</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>96.62</td>\n",
       "      <td>97.656</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0</td>\n",
       "      <td>4.086e-18</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>98.84</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0</td>\n",
       "      <td>4.693e-08</td>\n",
       "      <td>Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>94.77</td>\n",
       "      <td>97.266</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0</td>\n",
       "      <td>2.988e-15</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    regularizer_rate  final_acc  final_acc_train  final_test_loss  acc_color  \\\n",
       "33               0.0      73.79          100.000            1.118          0   \n",
       "61               0.0      70.52          100.000            1.592          0   \n",
       "7                0.0      65.15          100.000            2.127          0   \n",
       "45               0.1      62.44          100.000            2.744          0   \n",
       "57               0.1      61.78          100.000            2.275          0   \n",
       "36               0.1      70.14          100.000            1.592          0   \n",
       "20               0.1      61.82          100.000            2.871          0   \n",
       "17               0.1      97.89           99.609            0.067          0   \n",
       "31               0.1      62.82          100.000            2.118          0   \n",
       "11               0.1      98.44           99.609            0.047          0   \n",
       "16               0.1      59.98          100.000            2.181          0   \n",
       "32               1.0      74.25          100.000            1.169          0   \n",
       "51               1.0      51.92          100.000            3.848          0   \n",
       "53               1.0      71.23          100.000            2.106          0   \n",
       "65               1.0      69.65          100.000            1.938          0   \n",
       "18               1.0      56.49          100.000            2.728          0   \n",
       "34               1.0      60.07          100.000            2.291          0   \n",
       "74              10.0      97.75           99.219            0.075          0   \n",
       "2               10.0      85.21          100.000            0.708          0   \n",
       "28              10.0      57.57          100.000            3.115          0   \n",
       "26              10.0      74.62          100.000            1.452          0   \n",
       "24              10.0      69.79          100.000            1.692          0   \n",
       "73              10.0      54.21          100.000            3.929          0   \n",
       "21              10.0      88.02          100.000            0.382          0   \n",
       "47              10.0      56.87          100.000            2.873          0   \n",
       "72              10.0      73.21          100.000            1.269          0   \n",
       "6               10.0      72.70          100.000            1.713          0   \n",
       "67              10.0      98.04           99.219            0.066          0   \n",
       "4               10.0      97.85           99.219            0.073          0   \n",
       "35             100.0      74.54          100.000            1.207          0   \n",
       "..               ...        ...              ...              ...        ...   \n",
       "9             1000.0      98.34           99.219            0.047          0   \n",
       "12            1000.0      98.06           99.609            0.062          0   \n",
       "75            1000.0      97.66           99.609            0.075          0   \n",
       "19            1000.0      10.09           42.188            3.793          0   \n",
       "22            1000.0      99.01          100.000            0.030          0   \n",
       "37            1000.0      98.80          100.000            0.038          0   \n",
       "13           10000.0      97.40           99.219            0.079          0   \n",
       "14           10000.0      97.40           98.828            0.082          0   \n",
       "66           10000.0      10.09           42.188            9.169          0   \n",
       "15           10000.0      97.32           98.828            0.085          0   \n",
       "44           10000.0      97.15           98.828            0.087          0   \n",
       "59           10000.0      97.58           98.828            0.078          0   \n",
       "43           10000.0      97.62           98.828            0.071          0   \n",
       "23           10000.0      99.20          100.000            0.024          0   \n",
       "52           10000.0       9.74           42.188            9.776          0   \n",
       "48           10000.0      10.09           42.188           10.729          0   \n",
       "49           10000.0      99.15          100.000            0.024          0   \n",
       "29           10000.0      99.25          100.000            0.022          0   \n",
       "1           100000.0      10.09           42.188           15.527          0   \n",
       "3           100000.0      96.09           97.266            0.128          0   \n",
       "5           100000.0      96.42           97.656            0.118          0   \n",
       "40          100000.0      10.09           42.188           15.302          0   \n",
       "60          100000.0      99.23          100.000            0.024          0   \n",
       "39          100000.0      96.06           97.656            0.122          0   \n",
       "54          100000.0      99.17           99.609            0.026          0   \n",
       "63          100000.0       9.74           42.188           15.954          0   \n",
       "55          100000.0      96.45           97.656            0.115          0   \n",
       "30          100000.0      96.62           97.656            0.105          0   \n",
       "50          100000.0      98.84          100.000            0.034          0   \n",
       "68          100000.0      94.77           97.266            0.161          0   \n",
       "\n",
       "     final_cd        method  \n",
       "33  0.000e+00  ExpectedGrad  \n",
       "61  0.000e+00  ExpectedGrad  \n",
       "7   0.000e+00  ExpectedGrad  \n",
       "45  1.090e-03            CD  \n",
       "57  7.152e-06          Grad  \n",
       "36  7.907e-04            CD  \n",
       "20  2.807e-04            CD  \n",
       "17  6.208e-02  ExpectedGrad  \n",
       "31  2.175e-06          Grad  \n",
       "11  6.688e-02  ExpectedGrad  \n",
       "16  5.214e-05          Grad  \n",
       "32  1.563e-05            CD  \n",
       "51  3.185e-05          Grad  \n",
       "53  5.303e-05            CD  \n",
       "65  7.408e-05            CD  \n",
       "18  1.554e-05          Grad  \n",
       "34  1.941e-04          Grad  \n",
       "74  4.846e-03  ExpectedGrad  \n",
       "2   2.714e-06            CD  \n",
       "28  2.035e-05          Grad  \n",
       "26  2.711e-05            CD  \n",
       "24  1.374e-05            CD  \n",
       "73  2.467e-06          Grad  \n",
       "21  3.077e-06            CD  \n",
       "47  2.725e-05          Grad  \n",
       "72  2.281e-06            CD  \n",
       "6   1.081e-05            CD  \n",
       "67  3.728e-03  ExpectedGrad  \n",
       "4   5.343e-03  ExpectedGrad  \n",
       "35  2.390e-06          Grad  \n",
       "..        ...           ...  \n",
       "9   4.050e-08            CD  \n",
       "12  5.580e-08            CD  \n",
       "75  1.146e-08            CD  \n",
       "19  5.215e-04  ExpectedGrad  \n",
       "22  5.458e-07          Grad  \n",
       "37  1.359e-06          Grad  \n",
       "13  1.184e-14            CD  \n",
       "14  2.441e-14            CD  \n",
       "66  3.153e-05  ExpectedGrad  \n",
       "15  1.354e-13            CD  \n",
       "44  6.419e-13            CD  \n",
       "59  1.846e-14            CD  \n",
       "43  5.007e-14            CD  \n",
       "23  1.090e-08          Grad  \n",
       "52  6.755e-05  ExpectedGrad  \n",
       "48  4.548e-05  ExpectedGrad  \n",
       "49  1.876e-08          Grad  \n",
       "29  2.965e-08          Grad  \n",
       "1   7.296e-06  ExpectedGrad  \n",
       "3   2.012e-17            CD  \n",
       "5   4.018e-16            CD  \n",
       "40  4.012e-06  ExpectedGrad  \n",
       "60  8.960e-10          Grad  \n",
       "39  7.081e-20            CD  \n",
       "54  1.205e-08          Grad  \n",
       "63  7.172e-06  ExpectedGrad  \n",
       "55  1.313e-18            CD  \n",
       "30  4.086e-18            CD  \n",
       "50  4.693e-08          Grad  \n",
       "68  2.988e-15            CD  \n",
       "\n",
       "[77 rows x 7 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "concise_results = results_save.groupby(by = ['method','regularizer_rate']).mean()\n",
    "concise_results.columns = ['Test accuracy', 'Train accuracy', 'Test loss', 'Color accuracy', 'CD']\n",
    "# with open(oj(save_path, \"color_mnist.text\"), 'w') as f:\n",
    "#           f.write(concise_results.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concise_results_for_save = concise_results[['Test accuracy']]#, 'Color accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">CD</th>\n",
       "      <th>0.1</th>\n",
       "      <td>64.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>71.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>77.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>89.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>97.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>97.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000.0</th>\n",
       "      <td>96.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ExpectedGrad</th>\n",
       "      <th>0.0</th>\n",
       "      <td>69.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>98.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>97.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>88.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>9.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>9.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000.0</th>\n",
       "      <td>9.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Grad</th>\n",
       "      <th>0.1</th>\n",
       "      <td>61.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>56.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>56.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>73.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>98.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>99.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000.0</th>\n",
       "      <td>99.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Test accuracy\n",
       "method       regularizer_rate               \n",
       "CD           0.1                      64.800\n",
       "             1.0                      71.710\n",
       "             10.0                     77.258\n",
       "             100.0                    89.820\n",
       "             1000.0                   97.977\n",
       "             10000.0                  97.412\n",
       "             100000.0                 96.068\n",
       "ExpectedGrad 0.0                      69.820\n",
       "             0.1                      98.165\n",
       "             10.0                     97.880\n",
       "             100.0                    88.703\n",
       "             1000.0                    9.983\n",
       "             10000.0                   9.973\n",
       "             100000.0                  9.973\n",
       "Grad         0.1                      61.527\n",
       "             1.0                      56.160\n",
       "             10.0                     56.217\n",
       "             100.0                    73.987\n",
       "             1000.0                   98.927\n",
       "             10000.0                  99.200\n",
       "             100000.0                 99.080"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concise_results_for_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcd1ee9128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize = (8,5))\n",
    "ax.plot(results_save[results_save.method == 'CD'].groupby(by = ['regularizer_rate']).mean()[ 'final_acc'], label = 'CD')\n",
    "ax.plot(results_save[results_save.method == 'Grad'].groupby(by = ['regularizer_rate']).mean()[ 'final_acc'], label = 'Grad')\n",
    "plt.xscale('log')\n",
    "ax.set_ylabel(\"Accuracy\");\n",
    "ax.set_xlabel(\"Regularizer rate\");\n",
    "ax.set_ylim(0,100)\n",
    "fig.legend(loc='center')\n",
    "fig.suptitle(\"Accuracy on decoy MNIST\")\n",
    "save_path = \"../results_for_export\"\n",
    "fig.savefig(oj(save_path, \"decoyMNIST_grayscale\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(oj(save_path, 'colormnist_decoy.tex'), 'w') as f:\n",
    "          f.write(concise_results_for_save.to_latex(index  = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    def logits(self, x):\n",
    "    \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return(test_loss, 100.*correct / len(test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "test_x_tensor = torch.Tensor(np.load(oj(\"../data/ColorMNIST\", \"test_x.npy\")))\n",
    "test_y_color= torch.Tensor(np.load(oj(\"../data/ColorMNIST\", \"test_y_color.npy\"))).type(torch.int64)\n",
    "test_dataset_color = utils.TensorDataset(test_x_tensor,test_y_color) # create your datset\n",
    "\n",
    "test_loader_color = utils.DataLoader(test_dataset_color,\n",
    "        batch_size=256, shuffle=True, **kwargs) # create your dataloader\n",
    "\n",
    "test_net = Net()\n",
    "test_net = test_net.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_color_list = []\n",
    "loss_color_list = []\n",
    "for i in range(len(results)):\n",
    "    test_net.load_state_dict(results.model_weights[i])\n",
    "    loss_col, acc_col = test(test_net, 0, test_loader_color, 0)\n",
    "    acc_color_list.append(acc_col)\n",
    "    loss_color_list.append(loss_col)\n",
    "results[\"acc_color\"] =[x for x in acc_color_list]\n",
    "results[\"loss_color\"] =[x for x in loss_color_list]               \n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th>acc_color</th>\n",
       "      <th>loss_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>9.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>14.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9.46</td>\n",
       "      <td>10.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>11.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>11.14</td>\n",
       "      <td>8.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>13.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>9.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>8.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>13.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>14.17</td>\n",
       "      <td>7.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>41.73</td>\n",
       "      <td>5.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>33.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>26.12</td>\n",
       "      <td>6.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>2.307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regularizer_rate  acc_color  loss_color\n",
       "0                0.0       2.05       9.769\n",
       "1                0.0       0.01      15.921\n",
       "16               0.0       0.00      16.647\n",
       "3                0.0       0.12      14.022\n",
       "11               0.0       0.16      11.670\n",
       "18               0.1       9.46      10.251\n",
       "8                0.1       0.57      11.895\n",
       "9                0.1      11.14       8.119\n",
       "4                0.1       0.03      13.667\n",
       "19               0.1       0.01      11.923\n",
       "6                1.0       6.44       9.794\n",
       "5                1.0       4.16       8.923\n",
       "15               1.0       0.01      14.084\n",
       "2                1.0       0.00      17.706\n",
       "17               1.0       0.04      13.142\n",
       "10              10.0      14.17       7.543\n",
       "12              10.0      41.73       5.218\n",
       "13              10.0      37.67      33.525\n",
       "14              10.0      26.12       6.919\n",
       "7              100.0      10.09       2.307"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[['regularizer_rate',\"acc_color\",'loss_color']].sort_values(by = ['regularizer_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "test_x_tensor = torch.Tensor(np.load(oj(\"../data/ColorMNIST\", \"test_x.npy\")))\n",
    "test_y_color= torch.Tensor(np.load(oj(\"../data/ColorMNIST\", \"test_y.npy\"))).type(torch.int64)\n",
    "test_dataset_color = utils.TensorDataset(test_x_tensor,test_y_color) # create your datset\n",
    "\n",
    "test_loader_color = utils.DataLoader(test_dataset_color,\n",
    "        batch_size=1, shuffle=True, **kwargs) # create your dataloader\n",
    "\n",
    "test_net = Net()\n",
    "test_net = test_net.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "def test_fool( model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            if i >=10:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return(test_loss, 100.*correct / len(test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(test_loader_color):\n",
    "        if i >=10:\n",
    "            break\n",
    "        data, target = data.to(0), target.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = foolbox.models.PyTorchModel(\n",
    "    test_net, bounds=(-1, 1), num_classes=10, preprocessing=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.local/lib/python3.6/site-packages/foolbox/attacks/base.py:129: UserWarning: Not running the attack because the original input is already misclassified and the adversarial thus has a distance of 0.\n",
      "  warnings.warn('Not running the attack because the original input'\n"
     ]
    }
   ],
   "source": [
    "attack = foolbox.attacks.FGSM(fmodel)\n",
    "adversarial = attack(data[0].cpu().numpy(), target.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-1c85ee0817e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0macc_color_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss_color_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fool\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macc_color_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# results[\"loss_color\"] =[x for x in loss_color_list]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu_usage/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu_usage/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu_usage/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu_usage/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4001\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "acc_color_list = []\n",
    "loss_color_list = []\n",
    "for i in range(len(results[:4])):\n",
    "    test_net.load_state_dict(results.model_weights[i])\n",
    "    loss_col, acc_col = test(test_net, 0, test_loader_color, 0)\n",
    "    acc_color_list.append(acc_col)\n",
    "    loss_color_list.append(loss_col)\n",
    "results[\"fool\"] =[x for x in acc_color_list]\n",
    "# results[\"loss_color\"] =[x for x in loss_color_list]               \n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:01, 6222032.49it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 104359.74it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 1819044.76it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 39112.63it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prob_set = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ]))\n",
    "prob = np.zeros((28,28))\n",
    "for i in range(500):\n",
    "    prob +=prob_set[i][0][0].numpy()\n",
    "prob/=prob.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efccf303d68>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efccf4abcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train-images-idx3-ubyte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_usage)",
   "language": "python",
   "name": "gpu_usage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
