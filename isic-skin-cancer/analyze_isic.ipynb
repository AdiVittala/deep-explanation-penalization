{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from os.path import join as oj\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from utils import load_precalculated_dataset,get_output, load_img_dataset,get_auc_f1,calc_weights\n",
    "import numpy as np\n",
    "from torchvision import  transforms\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from numpy.random import randint\n",
    "import time\n",
    "from torchvision import models\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "pd.set_option('precision', 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../results_for_export\"\n",
    "trained_model_folder = '../models/ISIC_new'\n",
    "fnames = sorted([oj(trained_model_folder, fname) for fname in os.listdir(trained_model_folder) if 'pkl'  in fname]) \n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in (fnames)] \n",
    "results = pd.concat(results_list, axis=1, sort = True).T.infer_objects() \n",
    "idx_best_loss = [np.asarray(x).argmax() for x in results['val_acc_history']]  \n",
    "results['final_acc'] = [x[idx_best_loss[i]] for i,x in enumerate(results['val_acc_history'])] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regularizer rate of -1 indicates that only images with no patches were used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results[['regularizer_rate',\n",
    "                       'final_acc', \n",
    "                       'AUC (no patches)',\n",
    "                       'F1 score (no patches)',\n",
    "                       'AUC (patches)',\n",
    "                       'F1 score (patches)']].groupby('regularizer_rate').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the best network for each to visualize heatmaps \n",
    "results[['regularizer_rate','AUC (patches)','pid']][results.regularizer_rate >=0].sort_values('AUC (patches)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate ROC AUC\n",
    "Needs GPU enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets,_ = load_precalculated_dataset(\"../data/ISIC/calculated_features\")\n",
    "device = torch.device(0)\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier[-1] = nn.Linear(4096, 2)\n",
    "model = model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_nopatches_dict = {}\n",
    "auc_nopatches_dict = {}\n",
    "f1_patches_dict = {}\n",
    "auc_patches_dict = {}\n",
    "for index, row in results[['regularizer_rate','pid',]].iterrows():\n",
    "    fname = oj(trained_model_folder, str(row['pid']) + '.pt')\n",
    "    auc_nopatches_dict[row['pid']], f1_nopatches_dict[row['pid']] = get_auc_f1(model, datasets['test_no_patches'], fname = fname, )\n",
    "    auc_patches_dict[row['pid']], f1_patches_dict[row['pid']] = get_auc_f1(model, datasets['test'], fname = fname, )\n",
    "    \n",
    "# update values \n",
    "results['AUC (no patches)'] =[auc_nopatches_dict[x] for x in results['pid']]\n",
    "results['F1 score (no patches)'] =[f1_nopatches_dict[x] for x in results['pid']]\n",
    "results['AUC (patches)'] =[auc_patches_dict[x] for x in results['pid']]\n",
    "results['F1 score (patches)'] =[f1_patches_dict[x] for x in results['pid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM\n",
    "Needs GPU enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../pytorch-cnn-visualizations/src\")\n",
    "from tqdm import tqdm_notebook\n",
    "from gradcam import GradCam\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from utils import load_img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset = load_img_dataset(\"../data/ISIC/processed/\") # this only loads the test set\n",
    "mean = np.asarray([0.485, 0.456, 0.406]) \n",
    "std = np.asarray([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the pid's are determined randomly, they need to be filled in in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_no_reg = models.vgg16(pretrained=True)\n",
    "model_no_reg.classifier[-1] = nn.Linear(4096, 2)\n",
    "model_no_reg = model_no_reg.eval()\n",
    "model_no_reg.classifier.load_state_dict(torch.load('../models/ISIC_new/18378132135284132533.pt')); # best performing vanilla model\n",
    "model_reg = models.vgg16(pretrained=True)\n",
    "model_reg.classifier[-1] = nn.Linear(4096, 2)\n",
    "model_reg = model_reg.eval()\n",
    "model_reg.classifier.load_state_dict(torch.load('../models/ISIC_new/43348406653761550146.pt')); # best performing CDEP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list_all = [img_dataset[i][0] for i in range(1000) ]\n",
    "my_list_targets_all = [img_dataset[i][1] for i in range(1000) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = model_reg.cuda()\n",
    "model_no_reg = model_no_reg.cuda()\n",
    "\n",
    "grad_cam_noreg = GradCam(model_no_reg, target_layer=29)\n",
    "grad_cam_reg = GradCam(model_reg, target_layer=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = []\n",
    "for img, target in tqdm(zip(my_list_all[:1000], my_list_targets_all[:1000])):\n",
    "    img.requires_grad= True\n",
    "    test_img = img.cuda()\n",
    "    test_img = test_img[None, :, :224, :224]\n",
    "    img_np = img[:, :224, :224].detach().cpu().numpy().transpose(1,2,0)*std[None, None, :] + mean[None, None, :]\n",
    "    reg_saliency = grad_cam_reg.generate_cam(test_img, target)\n",
    "    vanilla_saliency = grad_cam_noreg.generate_cam(test_img, target)\n",
    "    triples.append((img_np, vanilla_saliency, reg_saliency, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize GradCAM for both networks to see what each model has learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.reset_orig()\n",
    "idxs = [1,2] # first ids that have a patch\n",
    "num_rows = len(idxs)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows,3, figsize=  (4.2*3, num_rows*3))\n",
    "\n",
    "for i, (idx) in enumerate(idxs):\n",
    "    original_img, vanilla_sal, reg_sal, true_class = triples[idx]\n",
    "\n",
    "    axes[i,0].imshow(np.clip(original_img,0,1))\n",
    "    axes[i,0].tick_params(axis='both', which='both', bottom=False, left = False, top=False, labelbottom=False, labelleft = False)\n",
    "\n",
    "    axes[i,1].imshow( vanilla_sal, cmap = plt.get_cmap(\"viridis\"),)\n",
    "    axes[i,1].tick_params(axis='both', which='both', bottom=False, left = False, top=False, labelbottom=False, labelleft = False)\n",
    "    axes[i,2].imshow(reg_sal, cmap =plt.get_cmap(\"viridis\"))\n",
    "\n",
    "    axes[i,2].tick_params(axis='both', which='both', bottom=False, left = False, top=False, labelbottom=False, labelleft = False)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = \"../results_for_export\"\n",
    "# fig.savefig(oj(save_path,\"gradCAM\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also visualize some samples that have hairs/rulers in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_triples = [x for x in triples if x[3] ==1]\n",
    "no_cancer_triples = [x for x in triples if x[3] ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "num_rows = 2\n",
    "fig, axes = plt.subplots(ncols=3, nrows = num_rows, figsize=  (3*3, num_rows*3))\n",
    "i_small  =0 \n",
    "for i, (original_img, vanilla_sal, reg_sal, true_class) in enumerate(cancer_triples[:num_rows]):\n",
    "    # highlighting works the other way around\n",
    "    vanilla_sal = 1- vanilla_sal\n",
    "    reg_sal = 1- reg_sal\n",
    "\n",
    "    axes[i,0].imshow(np.clip(original_img,0,1))\n",
    "    axes[i,0].tick_params(axis='both', which='both', bottom=False, left = False, top=False, labelbottom=False, labelleft = False)\n",
    "\n",
    "    axes[i,1].imshow(vanilla_sal[:, :, None]*np.clip(original_img,0,1))\n",
    "    axes[i,1].tick_params(axis='both', which='both', bottom=False, left = False, top=False, labelbottom=False, labelleft = False)\n",
    "\n",
    "    axes[i,2].imshow(reg_sal[:, :, None]*np.clip(original_img,0,1))\n",
    "    axes[i,2].tick_params(axis='both', which='both', bottom=False, left = False, top=False, labelbottom=False, labelleft = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_usage)",
   "language": "python",
   "name": "gpu_usage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
